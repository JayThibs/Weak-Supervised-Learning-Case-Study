{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with PyTorch using Azure Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import azureml\n",
    "import shutil\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import cv2\n",
    "import urllib3 \n",
    "import zipfile\n",
    "\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.core import Workspace, Datastore, Experiment, Run, Environment, ScriptRunConfig\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, AksCompute, ComputeTarget\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "from azureml.core.webservice import Webservice, AksWebservice, AciWebservice\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Connect to the AML Workspace Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to workspace\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace:\",ws.name)\n",
    "\n",
    "# Connect to compute for training\n",
    "compute_target = ComputeTarget(workspace=ws, name=\"OptimusPrime\")\n",
    "print(\"Compute Target:\",compute_target.name)\n",
    "\n",
    "# Connect to the datastore for the training images\n",
    "ds = Datastore.get_default(ws)\n",
    "print(\"Datastore:\",ds.name)\n",
    "\n",
    "# Connect to the experiment\n",
    "exp = Experiment(workspace=ws, name='Simpsons-PyTorch')\n",
    "print(\"Experiment:\",exp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Download and extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset from Github\n",
    "data_url = \"https://github.com/hnky/dataset-lego-figures/raw/master/_download/train-and-validate.zip\"\n",
    "data_path = \"./data\"\n",
    "download_path = os.path.join(data_path,\"train-and-validate.zip\")\n",
    "if not os.path.exists(data_path):\n",
    "    os.mkdir(data_path,);\n",
    "urllib.request.urlretrieve(data_url, filename=download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the dataset\n",
    "zip_ref = zipfile.ZipFile(download_path, 'r')\n",
    "zip_ref.extractall(data_path)\n",
    "zip_ref.close()\n",
    "print(\"Data extracted in: {}\".format(data_path))\n",
    "\n",
    "os.remove(download_path)\n",
    "print(\"Downloaded file removed: {}\".format(download_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Upload the data to AML datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Upload all the data to the datastore\n",
    "ds.upload(src_dir=data_path, target_path='simpsonslego-v3', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Create a Dataset from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a FileDataset pointing to files in 'simpsons' folder and its subfolders recursively\n",
    "datastore_paths = [(ds, 'simpsonslego-v3/**')]\n",
    "simpsons_ds = Dataset.File.from_files(path=datastore_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the dataset in AMLS\n",
    "simpsons_ds.register(workspace=ws,\n",
    "             name='LegoSimpsons-v3',\n",
    "             description='Simpsons dataset with Lego Figures',\n",
    "             create_new_version = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or connect to previous version of the data\n",
    "simpsons_ds = Dataset.get_by_name(ws, name='LegoSimpsons-v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Preview the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"data/train\"\n",
    "random_filenames = []\n",
    "for tag in os.listdir(path):\n",
    "    random_filenames.append(path+\"/\"+tag+\"/\"+random.choice([\n",
    "        x for x in os.listdir(os.path.join(path,tag))\n",
    "        if os.path.isfile(os.path.join(path,tag, x))\n",
    "    ]))\n",
    "\n",
    "grid = AxesGrid(plt.figure(1, (20,20)), 111, nrows_ncols=(4, 5), axes_pad=0, label_mode=\"1\")\n",
    "\n",
    "i = 0\n",
    "for img_name in random_filenames[0:10]:\n",
    "    \n",
    "    # Download image\n",
    "    image = cv2.imread(img_name)\n",
    "    image = cv2.resize(image, (352, 352))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Show image in grid\n",
    "    grid[i].imshow(image)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'trainingscripts/train.py'\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "### Add References\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "\n",
    "### Add run context for AML\n",
    "run = Run.get_context()\n",
    "\n",
    "### Parse incoming parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data-folder\", type=str, dest=\"data_folder\", help=\"data folder mounting point\", default=\"\")\n",
    "parser.add_argument(\"--num-epochs\", type=int, dest=\"num_epochs\", help=\"Number of epochs\", default=\"\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "data_path = args.data_folder\n",
    "num_epochs = args.num_epochs\n",
    "\n",
    "### Prepare the dataset\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_path, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            print(phase,running_loss,dataset_sizes[phase])\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            # Log the los / acc to AMLS\n",
    "            run.log(\"{} Loss\".format(phase), np.float(epoch_loss))\n",
    "            run.log(\"{} Acc\".format(phase), np.float(epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model_ft, './outputs/model.pth')\n",
    "\n",
    "# Save the labels\n",
    "with open('./outputs/labels.txt', 'w') as f:\n",
    "    f.writelines([\"%s\\n\" % item  for item in class_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create and run a PyTorch ScriptRunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_env_name = 'AzureML-PyTorch-1.6-GPU'\n",
    "\n",
    "pytorch_env = Environment.get(workspace=ws, name=curated_env_name)\n",
    "pytorch_env = pytorch_env.clone(new_name='pytorch-1.6-gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\n",
    "    '--data-folder', simpsons_ds.as_named_input('simpsons').as_mount(),\n",
    "    '--num-epochs', 15\n",
    "]\n",
    "\n",
    "project_folder = \"./trainingscripts\"\n",
    "\n",
    "config = ScriptRunConfig(\n",
    "    source_directory = project_folder, \n",
    "    script = 'train.py', \n",
    "    compute_target=compute_target,\n",
    "    environment = pytorch_env,\n",
    "    arguments=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the PyTorch estimator\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a historic run\n",
    "previousRunId = 'Simpsons-PyTorch_1603121847_d7954097'\n",
    "run = [r for r in exp.get_runs() if r.id == previousRunId][0]\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Register the model in Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(model_name='Simpsons-PyTorch',\n",
    "                           model_path='outputs',\n",
    "                           model_framework='PyTorch',\n",
    "                           model_framework_version='1.6',\n",
    "                           description=\"Simpsons PyTorch Classifier (From Jupyter Notebook)\",\n",
    "                           tags={'Conference':'Test 42'},\n",
    "                           resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=2))\n",
    "\n",
    "print(\"Model '{}' version {} registered \".format(model.name,model.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Download & Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.download(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import json\n",
    "import urllib\n",
    "from PIL import Image\n",
    "\n",
    "# Load the model\n",
    "loaded_model = torch.load(os.path.join('outputs','model.pth'), map_location=lambda storage, loc: storage)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Load the labels\n",
    "with open(os.path.join('outputs','labels.txt'), 'rt') as lf:\n",
    "    global labels\n",
    "    labels = [l.strip() for l in lf.readlines()]\n",
    "\n",
    "    \n",
    "def scoreImage(image_link):\n",
    "    # Load the image to predict\n",
    "    input_image = Image.open(image_link)\n",
    "\n",
    "    # Pre process\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(225),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "    # Predict the image\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        loaded_model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(input_batch)\n",
    "\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    probability = torch.nn.functional.softmax(output[0], dim=0).data.cpu().numpy().max()\n",
    "\n",
    "    #Return the result\n",
    "    return {\"label\": labels[index], \"probability\": round(probability*100,2)}\n",
    "\n",
    "\n",
    "\n",
    "path = r\"data/test\"\n",
    "grid = AxesGrid(plt.figure(1, (20,20)), 111, nrows_ncols=(4, 5), axes_pad=0, label_mode=\"1\")\n",
    "\n",
    "i = 0\n",
    "for img in os.listdir(path):\n",
    "    \n",
    "    #Score the image\n",
    "    result = scoreImage(os.path.join(path,img))\n",
    "    \n",
    "    # Download image\n",
    "    image = cv2.imread(os.path.join(path,img))\n",
    "    image = cv2.resize(image, (352, 352))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    cv2.rectangle(image, (0,260),(352,352),(255,255,255), -1)\n",
    "    cv2.putText(image, \"{} - {}%\".format(result['label'],result['probability']),(10, 300), cv2.FONT_HERSHEY_SIMPLEX, 0.65,(0,0,0),2,cv2.LINE_AA)    \n",
    "    \n",
    "    # Show image in grid\n",
    "    grid[i].imshow(image)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Deploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create a scoring script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'score.py'\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import json\n",
    "import urllib\n",
    "from PIL import Image\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'outputs','model.pth')\n",
    "    labels_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'outputs','labels.txt')\n",
    "    \n",
    "    print('Loading model...', end='')\n",
    "    model = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    model.eval()\n",
    "    \n",
    "    print('Loading labels...', end='')\n",
    "    with open(labels_path, 'rt') as lf:\n",
    "        global labels\n",
    "        labels = [l.strip() for l in lf.readlines()]\n",
    "    print(len(labels), 'found. Success!')\n",
    "\n",
    "    \n",
    "def run(input_data):\n",
    "    url = json.loads(input_data)['url']\n",
    "    urllib.request.urlretrieve(url, filename=\"tmp.jpg\")\n",
    "    \n",
    "    input_image = Image.open(\"tmp.jpg\")\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(225),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    probability = torch.nn.functional.softmax(output[0], dim=0).data.cpu().numpy().max()\n",
    "\n",
    "    result = {\"label\": labels[index], \"probability\": round(probability*100,2)}\n",
    "    os.remove(\"tmp.jpg\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Create an environment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv = Environment(name=\"simpsons-inference\")\n",
    "\n",
    "conda_dep = CondaDependencies()\n",
    "\n",
    "# Define the packages needed by the model and scripts\n",
    "#conda_dep.add_conda_package(\"tensorflow\")\n",
    "#conda_dep.add_conda_package(\"numpy\")\n",
    "#conda_dep.add_conda_package(\"scikit-learn\")\n",
    "\n",
    "# You must list azureml-defaults as a pip dependency\n",
    "conda_dep.add_pip_package(\"azureml-defaults\")\n",
    "conda_dep.add_pip_package(\"torch\")\n",
    "conda_dep.add_pip_package(\"torchvision\")\n",
    "conda_dep.add_pip_package(\"pillow==5.4.1\")\n",
    "\n",
    "# Adds dependencies to PythonSection of myenv\n",
    "myenv.python.conda_dependencies=conda_dep\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Create an Inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(\n",
    "    entry_script=\"score.py\", \n",
    "    environment=myenv\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Deploy to ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(ws, name='Simpsons-PyTorch')\n",
    "print(\"Loaded model version:\",model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a deployment config\n",
    "deploy_config = AciWebservice.deploy_configuration(\n",
    "                    cpu_cores = model.resource_configuration.cpu, \n",
    "                    memory_gb = model.resource_configuration.memory_in_gb,\n",
    "                    description='Simpson Lego Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model to an ACI\n",
    "aci_service = Model.deploy(ws, \n",
    "                name=\"simpsons-pt-aci\", \n",
    "                models = [model], \n",
    "                inference_config = inference_config, \n",
    "                deployment_config = deploy_config, \n",
    "                overwrite = True)\n",
    "\n",
    "aci_service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to previous deployment\n",
    "aci_service = AciWebservice(ws, \"simpsons-pt-aci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scoring endpoint:\",aci_service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Deploy to Azure Kuberneter Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_target = AksCompute(ws,\"Exodus\")\n",
    "\n",
    "deployment_config = AksWebservice.deploy_configuration(\n",
    "    cpu_cores = 1, \n",
    "    memory_gb = 2)\n",
    "\n",
    "aks_service = Model.deploy(workspace=ws, \n",
    "                       name=\"simpsons-pytorch-test-6\", \n",
    "                       models=[model], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=deployment_config, \n",
    "                       deployment_target=aks_target,\n",
    "                       overwrite=True)\n",
    "\n",
    "aks_service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Connect to a previous deployed service\n",
    "aks_service = [r for r in AksWebservice.list(ws) if r.name == 'simpsons-pytorch'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(aks_service.scoring_uri)\n",
    "aks_service.get_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Test the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'test-images-urls.txt'\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Krusty.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Bart.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Flanders.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Homer.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Lisa.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/marge.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Milhouse.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/MrBurns.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Wiggum.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from PIL import Image as ImagePil\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "import urllib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "F = plt.figure(1, (20,20))\n",
    "grid = AxesGrid(F, 111, nrows_ncols=(2, 3), axes_pad=0, label_mode=\"1\")\n",
    "\n",
    "with open('test-images-urls.txt', 'rt') as lf:\n",
    "    global testimages\n",
    "    testimages = [l.strip() for l in lf.readlines()]\n",
    "    \n",
    "def url_to_image(url):\n",
    "    with urllib.request.urlopen(url) as url:\n",
    "        s = url.read()\n",
    "    image = np.asarray(bytearray(s), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (352, 352))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "\n",
    "i = 0\n",
    "for img_name in testimages[0:6]:\n",
    "    \n",
    "    # Predict Url ACI\n",
    "    #result = aci_service.run(input_data=json.dumps({ \"url\": img_name}))\n",
    "    \n",
    "    # Predict Url AKS\n",
    "    result = aks_service.run(input_data=json.dumps({ \"url\": img_name}))\n",
    "\n",
    "    # Download image\n",
    "    img = url_to_image(img_name)\n",
    " \n",
    "    # Draw result on image\n",
    "    cv2.rectangle(img, (0,260),(352,352),(255,255,255), -1)\n",
    "    cv2.putText(img, \"{} - {}%\".format(result['label'],result['probability']),(10, 300), cv2.FONT_HERSHEY_SIMPLEX, 0.65,(0,0,0),2,cv2.LINE_AA)\n",
    "\n",
    "    # Show image in grid\n",
    "    grid[i].imshow(img)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test-images-urls.txt', 'rt') as lf:\n",
    "    global testimages\n",
    "    testimages = [l.strip() for l in lf.readlines()]\n",
    "\n",
    "print(testimages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
