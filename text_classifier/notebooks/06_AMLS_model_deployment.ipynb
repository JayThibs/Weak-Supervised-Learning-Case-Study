{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with PyTorch using Azure Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azureml.core'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3f03c9a56073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInferenceConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWorkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatastore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScriptRunConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'azureml.core'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azureml\n",
    "import shutil\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import urllib3\n",
    "import zipfile\n",
    "\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.core import Workspace, Datastore, Experiment, Run, Environment, ScriptRunConfig\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, AksCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "from azureml.core.webservice import Webservice, AksWebservice, AciWebservice\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Connect to the AML Workspace Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to workspace\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace:\",ws.name)\n",
    "\n",
    "# Connect to compute for training\n",
    "gpu_instance_name = \"weak-supervisor-gpu\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    gpu_instance = ComputeTarget(workspace=ws, name=gpu_instance_name)\n",
    "    print('Found existing gpu instance, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC12s_v3',\n",
    "max_nodes=1)\n",
    "    gpu_instance = ComputeTarget.create(ws, gpu_instance_name, compute_config)\n",
    "\n",
    "gpu_instance.wait_for_completion(show_output=True)\n",
    "\n",
    "print(\"Compute Target:\",gpu_instance.name)\n",
    "\n",
    "# Connect to the datastore for the training images\n",
    "ds = Datastore.get_default(ws)\n",
    "print(\"Datastore:\",ds.name)\n",
    "\n",
    "# Connect to the experiment\n",
    "exp = Experiment(workspace=ws, name='Weak-Supervision-fsdl')\n",
    "print(\"Experiment:\",exp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data by uploading dataset to Azure\n",
    "toxic_comments_ds = Dataset.get_by_name(ws, name='toxic_comments')\n",
    "df = toxic_comments_ds.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toxic = df[df[LABEL_COLUMNS].sum(axis=1) > 0]\n",
    "df_clean = df[df[LABEL_COLUMNS].sum(axis=1) == 0]\n",
    "\n",
    "train_df = pd.concat([\n",
    "  df_toxic.sample(2000, random_state=42),\n",
    "  df_clean.sample(2000, random_state=42)\n",
    "])\n",
    "\n",
    "train_df['label'] = np.where(train_df[LABEL_COLUMNS].sum(axis=1) == 0, 0, 1)\n",
    "train_df = train_df.drop(LABEL_COLUMNS, axis=1)\n",
    "train_df = train_df.rename(columns={\"comment_text\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_df = train_df.groupby('label').apply(lambda s: s.sample(500, random_state=123)).reset_index(level=0, drop=True)\n",
    "train_df.drop(fine_tune_df.index, inplace=True)\n",
    "\n",
    "train_df, test_df = train_test_split(train_df, test_size=0.25)\n",
    "val_df = test_df.sample(frac=0.1)\n",
    "test_df.drop(val_df.index, inplace=True)\n",
    "\n",
    "print('\\t Fine-Tune Set:', len(fine_tune_df), 'Valid:', len(val_df), '\\t', 'Train:', len(train_df), '\\t Test:', len(test_df),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'trainingscripts/train.py'\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizerFast as BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.functional import accuracy, f1, auroc\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, BackboneFinetuning, QuantizationAwareTraining, ModelPruning\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "RANDOM_SEED = 42\n",
    "pl.seed_everything(RANDOM_SEED)\n",
    "# lightning plus wandb\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import gc\n",
    "\n",
    "### Add References\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "\n",
    "### Add run context for AML\n",
    "run = Run.get_context()\n",
    "\n",
    "### Parse incoming parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data-folder\", type=str, dest=\"data_folder\", help=\"data folder mounting point\", default=\"\")\n",
    "parser.add_argument(\"--num-epochs\", type=int, dest=\"num_epochs\", help=\"Number of epochs\", default=\"\")\n",
    "parser.add_argument(\"--max_token_count\", type=int, dest=\"max_token_count\", help=\"max_token_count\", default=\"\")\n",
    "parser.add_argument(\"--batch_size\", type=int, dest=\"batch_size\", help=\"batch_size\", default=\"\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "data_path = args.data_folder\n",
    "num_epochs = args.num_epochs\n",
    "\n",
    "class ToxicCommentsDataset(Dataset):\n",
    "\n",
    "  def __init__(\n",
    "    self, \n",
    "    data: pd.DataFrame,\n",
    "    tokenizer: DistilBertForSequenceClassification,\n",
    "    max_token_len: int = 128\n",
    "  ):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.data = data\n",
    "    self.max_token_len = max_token_len\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, index: int):\n",
    "    data_row = self.data.iloc[index]\n",
    "\n",
    "    comment_text = data_row.text\n",
    "    labels = data_row['label']\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      comment_text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_token_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding=\"max_length\",\n",
    "      truncation=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "      comment_text=comment_text,\n",
    "      input_ids=encoding[\"input_ids\"].flatten(),\n",
    "      attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "      labels=labels\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset = ToxicCommentsDataset(\n",
    "  fine_tune_df,\n",
    "  tokenizer=tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "\n",
    "class ToxicCommentDataModule(pl.LightningDataModule):\n",
    "\n",
    "  def __init__(self, train_df, test_df, tokenizer, batch_size=4, max_token_len=128):\n",
    "    super().__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.train_df = train_df\n",
    "    self.test_df = test_df\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_token_len = max_token_len\n",
    "\n",
    "  def setup(self, stage=None):\n",
    "    self.train_dataset = ToxicCommentsDataset(\n",
    "      self.train_df,\n",
    "      self.tokenizer,\n",
    "      self.max_token_len\n",
    "    )\n",
    "\n",
    "    self.test_dataset = ToxicCommentsDataset(\n",
    "      self.test_df,\n",
    "      self.tokenizer,\n",
    "      self.max_token_len\n",
    "    )\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.train_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=2\n",
    "    )\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      num_workers=2\n",
    "    )\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      num_workers=2\n",
    "    )\n",
    "\n",
    "data_module = ToxicCommentDataModule(\n",
    "  fine_tune_df,\n",
    "  val_df,\n",
    "  tokenizer=tokenizer,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "\n",
    "\n",
    "class ToxicCommentTagger(pl.LightningModule):\n",
    "\n",
    "  def __init__(self, num_classes: int, input_dims=(BATCH_SIZE, MAX_TOKEN_COUNT), attn_mask=(BATCH_SIZE, MAX_TOKEN_COUNT), n_training_steps=None, n_warmup_steps=None):\n",
    "    super().__init__()\n",
    "    self.backbone = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "    # self.backbone = DistilBertForSequenceClassification.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "    self.classifier = nn.Linear(self.backbone.config.hidden_size, num_classes)\n",
    "    self.n_training_steps = n_training_steps\n",
    "    self.n_warmup_steps = n_warmup_steps\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # log hyperparameters\n",
    "    self.save_hyperparameters()\n",
    "\n",
    "    # compute the accuracy -- no need to roll your own!\n",
    "    self.train_acc = pl.metrics.Accuracy()\n",
    "    self.val_acc = pl.metrics.Accuracy()\n",
    "    self.test_acc = pl.metrics.Accuracy()\n",
    "    self.train_f1 = pl.metrics.F1(num_classes=num_classes)\n",
    "    self.val_f1 = pl.metrics.F1(num_classes=num_classes)\n",
    "    self.test_f1 = pl.metrics.F1(num_classes=num_classes)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels=None):\n",
    "    output = self.backbone(input_ids, attention_mask=attention_mask)\n",
    "    # output = torch.argmax(output.logits, 1)\n",
    "    # print(output.pooler_output)\n",
    "    output = self.classifier(output.pooler_output)\n",
    "    # print(output)\n",
    "    output = torch.sigmoid(output)\n",
    "    # print(output)\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "        loss = self.criterion(output, labels)\n",
    "    return loss, output\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "\n",
    "    loss, outputs = self(input_ids, attention_mask, labels) # calls self.forward\n",
    "    preds = torch.argmax(outputs, 1) # take the highest predicted number\n",
    "\n",
    "    self.train_acc(preds, labels)\n",
    "    self.train_f1(preds, labels)\n",
    "    self.log('train/loss_epoch', loss, on_step=False, on_epoch=True)\n",
    "    self.log('train/acc_epoch', self.train_acc, on_step=False, on_epoch=True)\n",
    "    self.log('train/f1_epoch', self.train_f1, on_step=False, on_epoch=True)\n",
    "\n",
    "    self.log(\"train_loss\", loss)\n",
    "    self.log(\"train_f1\", self.train_f1)\n",
    "    return {\"loss\": loss, \"predictions\": preds, \"labels\": labels}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    preds = torch.argmax(outputs, 1)\n",
    "\n",
    "    self.val_acc(preds, labels)\n",
    "    self.val_f1(preds, labels)\n",
    "    self.log('val/loss_epoch', loss, on_step=False, on_epoch=True)\n",
    "    self.log('val/acc_epoch', self.val_acc, on_step=False, on_epoch=True)\n",
    "    self.log('val/f1_epoch', self.val_f1, on_step=False, on_epoch=True)\n",
    "\n",
    "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "    self.log(\"val_f1\", self.val_f1, prog_bar=True, logger=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss\n",
    "\n",
    "  # def validation_epoch_end(self, validation_step_outputs):\n",
    "\n",
    "  # #   # Saving our model weights and biases every epoch.\n",
    "  # #   # This way, if we overfit, we can just roll back our weights to the saved weights at the best epoch\n",
    "  # #   dummy_input_dims = torch.zeros(self.hparams['input_dims'], dtype=torch.long, device=self.device)\n",
    "  # #   dummy_attn_mask = torch.zeros(self.hparams['attention_mask'], dtype=torch.long, device=self.device)\n",
    "  # #   input_names = [ \"input_dims\", \"attention_mask\" ]\n",
    "  # #   output_names = [ \"input_dims\", \"attention_mask\" ]\n",
    "  # #   dummy_input = [dummy_input_dims, dummy_attn_mask]\n",
    "  # #   model_filename = f'model_{str(self.global_step).zfill(5)}.onnx'\n",
    "  # #   torch.onnx.export(self, dummy_input, model_filename,\n",
    "  # #                     input_names=input_names,\n",
    "  # #                     output_names=output_names)\n",
    "  # #   wandb.save(model_filename)\n",
    "\n",
    "  #   # flatten validation step outputs as a pytorch tensor and turn into a histogram\n",
    "  #   flattened_logits = torch.flatten(torch.cat(validation_step_outputs))\n",
    "  #   self.logger.experiment.log(\n",
    "  #       {'valid/logits': wandb.Histogram(flattened_logits.to('cpu')),\n",
    "  #         'global_step': self.global_step}\n",
    "  #   )\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    preds = torch.argmax(outputs, 1)\n",
    "\n",
    "    self.test_acc(preds, labels)\n",
    "    self.test_f1(preds, labels)\n",
    "    self.log('test/loss_epoch', loss, on_step=False, on_epoch=True)\n",
    "    self.log('test/acc_epoch', self.test_acc, on_step=False, on_epoch=True)\n",
    "    self.log('test/f1_epoch', self.test_f1, on_step=False, on_epoch=True)\n",
    "\n",
    "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "    self.log(\"test_f1\", self.test_f1, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, self.parameters()), lr=2e-5)\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "      optimizer,\n",
    "      num_warmup_steps=self.n_warmup_steps,\n",
    "      num_training_steps=self.n_training_steps\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "      optimizer=optimizer,\n",
    "      lr_scheduler=dict(\n",
    "        scheduler=scheduler,\n",
    "        interval='step'\n",
    "      )\n",
    "    )\n",
    "\n",
    "\n",
    "steps_per_epoch=len(fine_tune_df) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "\n",
    "warmup_steps = total_training_steps // 5\n",
    "warmup_steps, total_training_steps\n",
    "\n",
    "model = ToxicCommentTagger(\n",
    "    'finetuned_multilingual_bert_1000ex_512tokens_8bs_pruning.ckpt'\n",
    "    num_classes=2,\n",
    "    n_warmup_steps=warmup_steps,\n",
    "    n_training_steps=total_training_steps\n",
    "    )\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    "    )\n",
    "\n",
    "multiplicative=lambda epoch: 1.1 # modifies learning rate after unfreeze\n",
    "backbone_finetuning = BackboneFinetuning(5, multiplicative) # freezes pretrained model until 5 epochs\n",
    "\n",
    "model_pruning = ModelPruning(\n",
    "    pruning_fn='l1_unstructured',\n",
    "    amount=0.1,\n",
    "    use_global_unstructured=True,\n",
    "    )\n",
    "\n",
    "wandb.login()\n",
    "wandb_logger = WandbLogger(project=\"weak-supervision-fsdl-project\", entity=\"weak-supervision-classifier-team\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=[wandb_logger],\n",
    "    log_every_n_steps=50,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks=[backbone_finetuning, model_pruning], # , early_stopping_callback, quantization_aware_training]\n",
    "    max_epochs=N_EPOCHS,\n",
    "    gpus=1,\n",
    "    deterministic=True,\n",
    "    progress_bar_refresh_rate=30,\n",
    "    precision=16\n",
    "    )\n",
    "\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "model_ckpt = \"finetuned_distill_bert_1000ex_256tokens_8bs_pruning.ckpt\"\n",
    "trainer.save_checkpoint(model_ckpt)\n",
    "wandb.save('*ckpt*')\n",
    "wandb.finish()\n",
    "\n",
    "# Save the model\n",
    "torch.save(model_ft, './outputs/model.pth')\n",
    "\n",
    "# Save the labels\n",
    "with open('./outputs/labels.txt', 'w') as f:\n",
    "    f.writelines([\"%s\\n\" % item  for item in class_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create and run a PyTorch ScriptRunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile conda_dependencies.yml\n",
    "\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - pip:\n",
    "    - azureml-defaults\n",
    "    - torch\n",
    "    - pytorch-lightning==1.2.8\n",
    "    - transformers==4.5.1\n",
    "    - wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment.from_conda_specification(name='pytorch-lightning-1.2.8-gpu', file_path='./conda_dependencies.yml')\n",
    "\n",
    "# specify a GPU base image\n",
    "env.docker.enabled = True\n",
    "env.docker.base_image = (\n",
    "    \"mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.2-cudnn8-ubuntu18.04\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\n",
    "    '--data-folder', toxic _ds.as_named_input('simpsons').as_mount(),\n",
    "    '--num-epochs', 10\n",
    "]\n",
    "\n",
    "project_folder = \"./trainingscripts\"\n",
    "\n",
    "config = ScriptRunConfig(\n",
    "    source_directory = project_folder, \n",
    "    script = 'train.py', \n",
    "    compute_target=gpu_instance,\n",
    "    environment = pytorch_env,\n",
    "    arguments=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the PyTorch estimator\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a historic run\n",
    "# previousRunId = ''\n",
    "# run = [r for r in exp.get_runs() if r.id == previousRunId][0]\n",
    "# RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Register the model in Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(model_name='Simpsons-PyTorch',\n",
    "                           model_path='outputs',\n",
    "                           model_framework='PyTorch',\n",
    "                           model_framework_version='1.6',\n",
    "                           description=\"Simpsons PyTorch Classifier (From Jupyter Notebook)\",\n",
    "                           tags={'Conference':'Test 42'},\n",
    "                           resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=2))\n",
    "\n",
    "print(\"Model '{}' version {} registered \".format(model.name,model.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Download & Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.download(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import json\n",
    "import urllib\n",
    "from PIL import Image\n",
    "\n",
    "# Load the model\n",
    "loaded_model = torch.load(os.path.join('outputs','model.pth'), map_location=lambda storage, loc: storage)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Load the labels\n",
    "with open(os.path.join('outputs','labels.txt'), 'rt') as lf:\n",
    "    global labels\n",
    "    labels = [l.strip() for l in lf.readlines()]\n",
    "\n",
    "    \n",
    "def scoreImage(image_link):\n",
    "    # Load the image to predict\n",
    "    input_image = Image.open(image_link)\n",
    "\n",
    "    # Pre process\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(225),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "    # Predict the image\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        loaded_model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(input_batch)\n",
    "\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    probability = torch.nn.functional.softmax(output[0], dim=0).data.cpu().numpy().max()\n",
    "\n",
    "    #Return the result\n",
    "    return {\"label\": labels[index], \"probability\": round(probability*100,2)}\n",
    "\n",
    "\n",
    "\n",
    "path = r\"data/test\"\n",
    "grid = AxesGrid(plt.figure(1, (20,20)), 111, nrows_ncols=(4, 5), axes_pad=0, label_mode=\"1\")\n",
    "\n",
    "i = 0\n",
    "for img in os.listdir(path):\n",
    "    \n",
    "    #Score the image\n",
    "    result = scoreImage(os.path.join(path,img))\n",
    "    \n",
    "    # Download image\n",
    "    image = cv2.imread(os.path.join(path,img))\n",
    "    image = cv2.resize(image, (352, 352))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    cv2.rectangle(image, (0,260),(352,352),(255,255,255), -1)\n",
    "    cv2.putText(image, \"{} - {}%\".format(result['label'],result['probability']),(10, 300), cv2.FONT_HERSHEY_SIMPLEX, 0.65,(0,0,0),2,cv2.LINE_AA)    \n",
    "    \n",
    "    # Show image in grid\n",
    "    grid[i].imshow(image)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Deploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create a scoring script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'score.py'\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import json\n",
    "import urllib\n",
    "from PIL import Image\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'outputs','model.pth')\n",
    "    labels_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'outputs','labels.txt')\n",
    "    \n",
    "    print('Loading model...', end='')\n",
    "    model = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    model.eval()\n",
    "    \n",
    "    print('Loading labels...', end='')\n",
    "    with open(labels_path, 'rt') as lf:\n",
    "        global labels\n",
    "        labels = [l.strip() for l in lf.readlines()]\n",
    "    print(len(labels), 'found. Success!')\n",
    "\n",
    "    \n",
    "def run(input_data):\n",
    "    url = json.loads(input_data)['url']\n",
    "    urllib.request.urlretrieve(url, filename=\"tmp.jpg\")\n",
    "    \n",
    "    input_image = Image.open(\"tmp.jpg\")\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(225),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    probability = torch.nn.functional.softmax(output[0], dim=0).data.cpu().numpy().max()\n",
    "\n",
    "    result = {\"label\": labels[index], \"probability\": round(probability*100,2)}\n",
    "    os.remove(\"tmp.jpg\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Create an environment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv = Environment(name=\"weak-supervision-inference\")\n",
    "\n",
    "conda_dep = CondaDependencies()\n",
    "\n",
    "# Define the packages needed by the model and scripts\n",
    "#conda_dep.add_conda_package(\"tensorflow\")\n",
    "#conda_dep.add_conda_package(\"numpy\")\n",
    "#conda_dep.add_conda_package(\"scikit-learn\")\n",
    "\n",
    "# You must list azureml-defaults as a pip dependency\n",
    "conda_dep.add_pip_package(\"azureml-defaults\")\n",
    "conda_dep.add_pip_package(\"torch\")\n",
    "conda_dep.add_pip_package(\"pytorch-lightning==1.2.8\")\n",
    "\n",
    "# Adds dependencies to PythonSection of myenv\n",
    "myenv.python.conda_dependencies=conda_dep\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Create an Inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(\n",
    "    entry_script=\"score.py\", \n",
    "    environment=myenv\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Deploy to ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(ws, name='Simpsons-PyTorch')\n",
    "print(\"Loaded model version:\",model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a deployment config\n",
    "deploy_config = AciWebservice.deploy_configuration(\n",
    "                    cpu_cores = model.resource_configuration.cpu, \n",
    "                    memory_gb = model.resource_configuration.memory_in_gb,\n",
    "                    description='Simpson Lego Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model to an ACI\n",
    "aci_service = Model.deploy(ws, \n",
    "                name=\"simpsons-pt-aci\", \n",
    "                models = [model], \n",
    "                inference_config = inference_config, \n",
    "                deployment_config = deploy_config, \n",
    "                overwrite = True)\n",
    "\n",
    "aci_service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to previous deployment\n",
    "aci_service = AciWebservice(ws, \"simpsons-pt-aci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scoring endpoint:\",aci_service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Deploy to Azure Kuberneter Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_target = AksCompute(ws,\"Exodus\")\n",
    "\n",
    "deployment_config = AksWebservice.deploy_configuration(\n",
    "    cpu_cores = 1, \n",
    "    memory_gb = 2)\n",
    "\n",
    "aks_service = Model.deploy(workspace=ws, \n",
    "                       name=\"simpsons-pytorch-test-6\", \n",
    "                       models=[model], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=deployment_config, \n",
    "                       deployment_target=aks_target,\n",
    "                       overwrite=True)\n",
    "\n",
    "aks_service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Connect to a previous deployed service\n",
    "aks_service = [r for r in AksWebservice.list(ws) if r.name == 'simpsons-pytorch'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(aks_service.scoring_uri)\n",
    "aks_service.get_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Test the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'test-images-urls.txt'\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Krusty.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Bart.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Flanders.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Homer.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Lisa.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/marge.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Milhouse.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/MrBurns.jpg\n",
    "https://raw.githubusercontent.com/hnky/dataset-lego-figures/master/_test/Wiggum.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from PIL import Image as ImagePil\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "import urllib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "F = plt.figure(1, (20,20))\n",
    "grid = AxesGrid(F, 111, nrows_ncols=(2, 3), axes_pad=0, label_mode=\"1\")\n",
    "\n",
    "with open('test-images-urls.txt', 'rt') as lf:\n",
    "    global testimages\n",
    "    testimages = [l.strip() for l in lf.readlines()]\n",
    "    \n",
    "def url_to_image(url):\n",
    "    with urllib.request.urlopen(url) as url:\n",
    "        s = url.read()\n",
    "    image = np.asarray(bytearray(s), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (352, 352))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "\n",
    "i = 0\n",
    "for img_name in testimages[0:6]:\n",
    "    \n",
    "    # Predict Url ACI\n",
    "    #result = aci_service.run(input_data=json.dumps({ \"url\": img_name}))\n",
    "    \n",
    "    # Predict Url AKS\n",
    "    result = aks_service.run(input_data=json.dumps({ \"url\": img_name}))\n",
    "\n",
    "    # Download image\n",
    "    img = url_to_image(img_name)\n",
    " \n",
    "    # Draw result on image\n",
    "    cv2.rectangle(img, (0,260),(352,352),(255,255,255), -1)\n",
    "    cv2.putText(img, \"{} - {}%\".format(result['label'],result['probability']),(10, 300), cv2.FONT_HERSHEY_SIMPLEX, 0.65,(0,0,0),2,cv2.LINE_AA)\n",
    "\n",
    "    # Show image in grid\n",
    "    grid[i].imshow(img)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test-images-urls.txt', 'rt') as lf:\n",
    "    global testimages\n",
    "    testimages = [l.strip() for l in lf.readlines()]\n",
    "\n",
    "print(testimages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3613jvsc74a57bd07f061771619cbf1b6795643f7c608e179b0c096b49ba2884d93968db10683f48",
   "display_name": "Python 3.6.13 64-bit ('fsdl2021labs': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "7f061771619cbf1b6795643f7c608e179b0c096b49ba2884d93968db10683f48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}