{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGgfoKVYnXPk"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/huggingface/transformers.git\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distilling Zero Shot Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMrUSGMI5MXZ"
   },
   "source": [
    "This notebook demonstrates how to use a script that provides a way to improve the speed and memory performance of a zero-shot classifier by training a more efficient student model from the zero-shot teacher's predictions over an unlabeled dataset.\n",
    "\n",
    "For a given sequence, the zero-shot classification pipeline requires each possible label to be fed through the large NLI model separately. This requirement slows results considerably, particularly for tasks with a large number of classes K.\n",
    "\n",
    "We'll use the dbpedia14's entity classification dataset for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "gUCM704I5u6E",
    "outputId": "aca08c17-7997-4d00-bf2a-7f7a40d2371f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce4d391380145878d01b03429377f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2183.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71cafc23f6b498bb5bf1ee75b114888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1288.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset d_bpedia14/dbpedia_14 (download: 65.18 MiB, generated: 191.44 MiB, post-processed: Unknown size, total: 256.62 MiB) to /Users/arian/.cache/huggingface/datasets/d_bpedia14/dbpedia_14/2.0.0/a70413e39e7a716afd0e90c9e53cb053691f56f9ef5fe317bd07f2c368e8e897...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680b217f039b4869bf45dd82fb298e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', max=1.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Dataset d_bpedia14 downloaded and prepared to /Users/arian/.cache/huggingface/datasets/d_bpedia14/dbpedia_14/2.0.0/a70413e39e7a716afd0e90c9e53cb053691f56f9ef5fe317bd07f2c368e8e897. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': ' Abbott of Farnham E D Abbott Limited was a British coachbuilding business based in Farnham Surrey trading under that name from 1929. A major part of their output was under sub-contract to motor vehicle manufacturers. Their business closed in 1972.',\n",
       " 'label': 0,\n",
       " 'title': 'E. D. Abbott Ltd'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "train, test = load_dataset('dbpedia_14', split=['train', 'test'])\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Company', 'EducationalInstitution', 'Artist', 'Athlete', 'OfficeHolder', 'MeanOfTransportation', 'Building', 'NaturalPlace', 'Village', 'Animal', 'Plant', 'Album', 'Film', 'WrittenWork']\n",
      "\n",
      "['Company', 'Educational Institution', 'Artist', 'Athlete', 'Office Holder', 'Mean Of Transportation', 'Building', 'Natural Place', 'Village', 'Animal', 'Plant', 'Album', 'Film', 'Written Work']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "original_labels = train.info.features[\"label\"].names\n",
    "zeroshot_labels = [re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", l) for l in original_labels]\n",
    "\n",
    "\n",
    "print(original_labels)\n",
    "print()\n",
    "print(zeroshot_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \" Schwan-STABILO is a German maker of pens for writing colouring and cosmetics as well as markers and highlighters for office use. It is the world's largest manufacturer of highlighter pens Stabilo Boss.\",\n",
       " 'label': 0,\n",
       " 'title': 'Schwan-Stabilo'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       content  title\n",
       "label                \n",
       "0        40000  40000\n",
       "1        40000  40000\n",
       "2        40000  40000\n",
       "3        40000  40000\n",
       "4        40000  40000\n",
       "5        40000  40000\n",
       "6        40000  40000\n",
       "7        40000  40000\n",
       "8        40000  40000\n",
       "9        40000  40000\n",
       "10       40000  40000\n",
       "11       40000  40000\n",
       "12       40000  40000\n",
       "13       40000  40000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby([\"label\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMZcx0dz61ef"
   },
   "source": [
    "### 🤗 Zero-shot classification pipeline\n",
    "\n",
    "The [zero-shot classification pipeline](https://huggingface.co/transformers/main_classes/pipelines.html#transformers.ZeroShotClassificationPipeline) is a tool withing 🤗 Transformers that can be used to classify text sequences out of the box, provided only a list of possible class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "zero_shot_classifier = pipeline('zero-shot-classification', model=\"roberta-large-mnli\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8_z-awr9LEb",
    "outputId": "6982c562-d142-40d3-c231-01f3d0516e4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': \"Schwan-STABILO is a German maker of pens for writing colouring and cosmetics as well as markers and highlighters for office use. It is the world's largest manufacturer of highlighter pens Stabilo Boss.\",\n",
       " 'labels': ['Company',\n",
       "  'Building',\n",
       "  'Village',\n",
       "  'Mean Of Transportation',\n",
       "  'Album',\n",
       "  'Artist',\n",
       "  'Film',\n",
       "  'Plant',\n",
       "  'Written Work',\n",
       "  'Office Holder',\n",
       "  'Educational Institution',\n",
       "  'Natural Place',\n",
       "  'Animal',\n",
       "  'Athlete'],\n",
       " 'scores': [0.26675543189048767,\n",
       "  0.16022440791130066,\n",
       "  0.08964039385318756,\n",
       "  0.06799466907978058,\n",
       "  0.06777624785900116,\n",
       "  0.05430350452661514,\n",
       "  0.050630487501621246,\n",
       "  0.044264644384384155,\n",
       "  0.04133811220526695,\n",
       "  0.040396228432655334,\n",
       "  0.034614574164152145,\n",
       "  0.0286851953715086,\n",
       "  0.028418727219104767,\n",
       "  0.02495739236474037]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"Schwan-STABILO is a German maker of pens for writing colouring and cosmetics as well as markers and highlighters for office use. It is the world's largest manufacturer of highlighter pens Stabilo Boss.\"\n",
    "class_names = zeroshot_labels\n",
    "zero_shot_classifier(sequence, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AB-0v4ep84vv"
   },
   "source": [
    "This method serves as a convenient out-of-the-box classifier. Unfortunately, the method is by necessity somewhat slow. This is partially due to the large underlying model being used, but more important is the fact that for this method to work, every possible sequence / class name pair must be fed through the model together. So in order to classify `N` sequences into `K` classes, the model has to be called `N*K` times (whereas a typical classifier would only be called `N` times). This makes the method comparatively slow, especially for settings with a large number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7h2uvu0F90_9",
    "outputId": "b4d7f004-29cf-422f-fc80-0bd84dc519f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 4 µs, total: 11 µs\n",
      "Wall time: 24.8 µs\n"
     ]
    }
   ],
   "source": [
    "# classify 1600 examples with K=4 classes\n",
    "%time\n",
    "for _ in range(100):\n",
    "    zero_shot_classifier([sequence] * 16, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-rBuO1_973y",
    "outputId": "cd53f383-c4e1-4047-ad10-a201060f978d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
      "Wall time: 16.2 µs\n"
     ]
    }
   ],
   "source": [
    "# # classify 1600 examples with K=8 classes\n",
    "# %time\n",
    "# expanded_class_names = class_names + [\"politics\", \"health\", \"food\", \"weather\"]\n",
    "# for _ in range(100):\n",
    "#     zero_shot_classifier([sequence] * 16, expanded_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTnrdYNI-zR5"
   },
   "source": [
    "As we can see, increasing the number of classes from `K=4` to `K=8` approximately doubles the inference time. This classification method is extremely useful, but ideally we'd like to speed up inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwQz_FPB_K4j"
   },
   "source": [
    "### Distilling a more efficient student model\n",
    "\n",
    "The best way to speed up inference is to **train a more efficient student model on the zero-shot classifier's predictions** over an unlabeled dataset. This can be done with the [`distill_classifier.py`](https://github.com/huggingface/transformers/blob/master/examples/research_projects/zero-shot-distillation/distill_classifier.py) script provided in the `transformers` repo.\n",
    "\n",
    "Given (1) an unlabeled corpus and (2) a set of `K` class names, this script allows a user to train a standard classification head with `K` output dimensions. The script generates a softmax distribution for the provided data & class names, and a student classifier is then fine-tuned on these proxy labels. The resulting student model can be used for classifying novel text instances into the previously specified `K` classes with an order-of-magnitude boost in inference speed plus decreased memory usage.\n",
    "\n",
    "Let's see how to do this with the [AG's News](https://huggingface.co/datasets/ag_news) topic classification dataset. The first thing we need is an unlabeled dataset (in reality AG's News is annotated of course, but we'll pretend and ignore the annotations for the sake of example). Let's put the sequences from the train set into a `txt` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mLet's setup this directory for W&B!\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "#!pip install wandb\n",
    "#!wandb init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup WandB and connect to team workspace\n",
    "import wandb\n",
    "wandb.init(project=\"weak-supervision-case-study\", entity=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "xykweYIWoy-6"
   },
   "outputs": [],
   "source": [
    "!mkdir dbmedia14\n",
    "with open(\"dbmedia14/train_unlabeled.txt\", 'w') as f:\n",
    "    for seq in train[\"content\"]:\n",
    "        f.write(seq + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560000 dbmedia14/train_unlabeled.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l dbmedia14/train_unlabeled.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 dbmedia14/class_names.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l dbmedia14/class_names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8zXcKPqApoG"
   },
   "source": [
    "The other thing the script needs is the names of the classes. We'll put these into their own newline-delimitted `txt` as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "6Gn5PidvAkHQ"
   },
   "outputs": [],
   "source": [
    "with open(\"dbmedia14/class_names.txt\", 'w') as f:\n",
    "    for label in class_names:\n",
    "        f.write(label + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dock/workspace/transformers/examples/research_projects/zero-shot-distillation\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0A11PttrBZgf"
   },
   "source": [
    "Now we can run the script. First the zero-shot model will loop through the data and generate (soft) proxy-labels, and then a student `DistilBert` model will be fine-tuned on these predictions. The student will then be saved in `./distilbert-base-uncased-agnews-student`. See the [script readme](https://github.com/huggingface/transformers/blob/master/examples/research_projects/zero-shot-distillation/README.md) for more information about the available script arguments.\n",
    "\n",
    "On a single P100, this will take about ~2 hours with the full training set of 130K examples. On a V100 with mixed precision (just pass `--fp16`), it will take ~30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "1. It fails to use the entire dataset. Need to run with subsets 1k, 10k of the training set. I will split the annotation script and the training script in too steps so it won't happen.  \n",
    "\n",
    "2. It takes about 8 hours to annotate the labels using zero shot distillation. The resulting training set with the labels fail to run the training phase because of memory I think. Need to debug that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ECt06ndcnpyb",
    "outputId": "a54094b8-83fb-4f69-a8c7-96c515393ee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"distill_classifier.py\", line 8, in <module>\n",
      "    from datasets import Dataset\n",
      "ModuleNotFoundError: No module named 'datasets'\n"
     ]
    }
   ],
   "source": [
    "!python distill_classifier.py \\\n",
    "--data_file ./dbmedia14/train_unlabeled_10k.txt \\\n",
    "--class_names_file ./dbmedia14/class_names.txt \\\n",
    "--hypothesis_template \"This text is about {}.\" \\\n",
    "--student_name_or_path distilbert-base-uncased \\\n",
    "--output_dir ./distilbert-base-uncased-dbmedia14-student \\\n",
    "--fp16 True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d2-ptlaF2M5"
   },
   "source": [
    "### Using the student model\n",
    "\n",
    "The resulting model can now be loaded and used like any other pre-trained model:\n",
    "\n",
    "(you can also use `\"joeddav/distilbert-base-uncased-agnews-student\"` to download this model from the hub if you want to try it without running whole script above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hwh61MsAGdEw",
    "outputId": "5ec862e9-4a6c-4e6e-ecf2-a768c9563be8"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./distilbert-base-uncased-dbmedia14-student\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./distilbert-base-uncased-dbmedia14-student\")\n",
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glxrI7uXGhI6"
   },
   "source": [
    "and even used trivially with a `TextClassificationPipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dAKVEuPEGXzF",
    "outputId": "b2f1a0be-9dbc-4a2d-b53d-e9677b5b2841"
   },
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "distilled_classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True, device=0)\n",
    "print(sequence)\n",
    "distilled_classifier(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoQ6hQe2Miu4"
   },
   "source": [
    "Let's compare the speed & accuracy of the two methods.\n",
    "\n",
    "Original zero-shot model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "65e7c2a2bfa84bb5af462e7525a2c8db",
      "39b11c030de449bc892afa1f1e5f36e2",
      "8b8583289b2a40e2b67d073f6a20507d",
      "90386ac483ca4e8983fc273c2ab4126c",
      "b89937e4985e49feaf68d03578043a90",
      "cfa8908bcc924a949db98fa53be4540f",
      "c48bd1b53b1b4206adaf20d0c0759e93",
      "61f3ff8b29014543be0bc2bb8be2ab87"
     ]
    },
    "id": "to7DOOp9LxlM",
    "outputId": "4b474035-3314-4374-f88f-0b61d9bf62dc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50099c2d72ed476cb5a38862b4aca652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=238.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teacher model accuracy: 69.33%\n",
      "Runtime:  221.37 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "start = time()\n",
    "batch_size = 32\n",
    "hypothesis_template = \"This text is about {}.\"\n",
    "preds = []\n",
    "for i in tqdm(range(0, len(test), batch_size)):\n",
    "    examples = test[i:i+batch_size]['text']\n",
    "    outputs = zero_shot_classifier(examples, class_names, hypothesis_template=hypothesis_template)\n",
    "    preds += [class_names.index(o['labels'][0]) for o in outputs]\n",
    "accuracy = np.mean(np.array(preds) == np.array(test['label']))\n",
    "print(f\"Teacher model accuracy: {accuracy*100:0.2f}%\")\n",
    "print(f\"Runtime: {time() - start : 0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o74qNjt-MOCI"
   },
   "source": [
    "Distilled student model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "899620103bc4450fbca7e59e45dcbc81",
      "0fbd3a194b284c0f87c1fac48ec0d023",
      "3030a8a6822c4ef78e5a0a0b8a7a0049",
      "ca78f7fab6854d2bb57747f966bf66bd",
      "253cbb88dc904c228a23217f5ef76f53",
      "a98d0be96c5b4252b3c9c3954843397d",
      "ec04d21385fc4332b7ac285b9c47dca9",
      "589eee9a1f414760b11587d4cbcb8943"
     ]
    },
    "id": "r4tuVf6VNLGg",
    "outputId": "fdb4e053-c963-4a6b-c49d-98f3db514531"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb1be57c18a4151ae0954fae7ffedc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distilled model accuracy: 70.79%\n",
      "Runtime:  11.95 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "batch_size = 128 # larger batch size bc distilled model is more memory efficient\n",
    "distilled_classifier.return_all_scores = False\n",
    "preds = []\n",
    "groundtruth = []\n",
    "for i in tqdm(range(0, len(test), batch_size)):\n",
    "    examples = test[i:i+batch_size]['text']\n",
    "    outputs = distilled_classifier(examples)\n",
    "    preds += [class_names.index(o['label']) for o in outputs]\n",
    "    groundtruth += test[i:i+batch_size]['label']\n",
    "accuracy = np.mean(np.array(preds) == np.array(test['label']))\n",
    "print(f\"Distilled model accuracy: {accuracy*100:0.2f}%\")\n",
    "print(f\"Runtime: {time() - start : 0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "IPyKernel not installed into interpreter Python 3.9.1 64-bit:/usr/local/bin/python3",
     "traceback": [
      "Error: IPyKernel not installed into interpreter Python 3.9.1 64-bit:/usr/local/bin/python3",
      "at v.installMissingDependencies (/Users/arian/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:244799)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "scores = {\n",
    "    \"macro\":{}, \"micro\":{}, \"weighted\":{}\n",
    "}\n",
    "\n",
    "for metric in scores:\n",
    "    scores[metric][\"precision\"], scores[metric][\"recall\"], scores[metric][\"f1\"], _ = \\\n",
    "    precision_recall_fscore_support(groundtruth, preds, average=metric)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "confusion_matrix = metrics.confusion_matrix(groundtruth, preds)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(groundtruth, preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Uhs--uSnuaf"
   },
   "source": [
    "As you can see, **the disitlled model gets similar accuracy on a held-out test set while running in 1/20th the time**. \n",
    "\n",
    "Lastly, you can share the distilled model with the community by [uploading it to the 🤗 Hub](https://huggingface.co/transformers/model_sharing.html). We've uploaded the distilled model from this notebook at [joeddav/distilbert-base-uncased-agnews-student](https://huggingface.co/joeddav/distilbert-base-uncased-agnews-student)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Distilling Zero Shot Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0fbd3a194b284c0f87c1fac48ec0d023": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "253cbb88dc904c228a23217f5ef76f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3030a8a6822c4ef78e5a0a0b8a7a0049": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a98d0be96c5b4252b3c9c3954843397d",
      "max": 60,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_253cbb88dc904c228a23217f5ef76f53",
      "value": 60
     }
    },
    "39b11c030de449bc892afa1f1e5f36e2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "589eee9a1f414760b11587d4cbcb8943": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61f3ff8b29014543be0bc2bb8be2ab87": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65e7c2a2bfa84bb5af462e7525a2c8db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b8583289b2a40e2b67d073f6a20507d",
       "IPY_MODEL_90386ac483ca4e8983fc273c2ab4126c"
      ],
      "layout": "IPY_MODEL_39b11c030de449bc892afa1f1e5f36e2"
     }
    },
    "899620103bc4450fbca7e59e45dcbc81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3030a8a6822c4ef78e5a0a0b8a7a0049",
       "IPY_MODEL_ca78f7fab6854d2bb57747f966bf66bd"
      ],
      "layout": "IPY_MODEL_0fbd3a194b284c0f87c1fac48ec0d023"
     }
    },
    "8b8583289b2a40e2b67d073f6a20507d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cfa8908bcc924a949db98fa53be4540f",
      "max": 238,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b89937e4985e49feaf68d03578043a90",
      "value": 238
     }
    },
    "90386ac483ca4e8983fc273c2ab4126c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61f3ff8b29014543be0bc2bb8be2ab87",
      "placeholder": "​",
      "style": "IPY_MODEL_c48bd1b53b1b4206adaf20d0c0759e93",
      "value": " 238/238 [03:15&lt;00:00,  1.22it/s]"
     }
    },
    "a98d0be96c5b4252b3c9c3954843397d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b89937e4985e49feaf68d03578043a90": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c48bd1b53b1b4206adaf20d0c0759e93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca78f7fab6854d2bb57747f966bf66bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_589eee9a1f414760b11587d4cbcb8943",
      "placeholder": "​",
      "style": "IPY_MODEL_ec04d21385fc4332b7ac285b9c47dca9",
      "value": " 60/60 [00:11&lt;00:00,  5.33it/s]"
     }
    },
    "cfa8908bcc924a949db98fa53be4540f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec04d21385fc4332b7ac285b9c47dca9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}