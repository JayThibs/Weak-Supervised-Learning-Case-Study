{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_toxicity_classification_snorkel_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM1DWvHdU2iT1wsCiMsWftS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayThibs/Weak-Supervised-Learning-Case-Study/blob/main/text_classifier/notebooks/05_toxicity_classification_snorkel_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saBb2bD7UD0s"
      },
      "source": [
        "# Creating a Binary Classification Dataset of the Toxicity Dataset with Snorkel\n",
        "\n",
        "In order to simplify the problem, we are going to turn this multi-label classification problem (does it contain any of these 'bad' labels?) to a binary classification problem (is it a 'bad' comment or not?).\n",
        "\n",
        "We've already trained a multi-label model for this problem in notebook 01, so why are we doing this? We are doing this for a few reasons:\n",
        "\n",
        "1. We want to test how well we can create labeling functions with Snorkel to build a dataset without knowing the labels.\n",
        "\n",
        "2. It takes time to create many labeling functions that create a useful dataset, and it takes longer if it's for a multi-class classification problem, and even longer for multi-label classification. Therefore, in the interest of time, we will make the classification binary.\n",
        "\n",
        "3. We want to try implementing Active Learning into our prototype and it will be simpler to start with a binary classification model.\n",
        "\n",
        "\n",
        "Some of the code is borrowed from:\n",
        "\n",
        "1. https://colab.research.google.com/drive/14Ea4lIzsn5EFvPpYKtWStXEByT9qmbkj?usp=sharing#scrollTo=acF4YRlQL8iz\n",
        "\n",
        "2. https://www.inovex.de/blog/snorkel-weak-superversion-german-texts/\n",
        "\n",
        "3. https://trishalaneeraj.github.io/2020-07-26/data-labeling-weak-supervision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6mQZscxROyY",
        "outputId": "00a96295-0dae-4394-c435-66b9b65097e6"
      },
      "source": [
        "!pip install snorkel --quiet\n",
        "!pip install datasets --quiet\n",
        "!pip install spacy --quiet\n",
        "!pip install pip install better-profanity --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 153kB 3.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8MB 25.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 36.8MB/s \n",
            "\u001b[?25h  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 225kB 4.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 19.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 20.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1HPT0lHR0ug"
      },
      "source": [
        "import pandas as pd\n",
        "from snorkel.labeling import labeling_function\n",
        "from snorkel.labeling import LabelingFunction\n",
        "from snorkel.labeling.lf.nlp import nlp_labeling_function\n",
        "from snorkel.preprocess import preprocessor\n",
        "from textblob import TextBlob\n",
        "from better_profanity import profanity\n",
        "from snorkel.labeling import PandasLFApplier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "import numpy as np\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkUrK_WuT7Zo"
      },
      "source": [
        "## Data\n",
        "\n",
        "Our dataset contains potentially offensive (toxic) comments and comes from the [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge). Let's start by download the data (from Google Drive):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-1azuNASAw2",
        "outputId": "a35e5282-1b07-4a14-d46f-2576c6482ca6"
      },
      "source": [
        "!gdown --id 1VuQ-U7TtggShMeuRSA_hzC8qGDl2LRkr"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VuQ-U7TtggShMeuRSA_hzC8qGDl2LRkr\n",
            "To: /content/toxic_comments.csv\n",
            "68.8MB [00:00, 84.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzTEoMaFUBS9"
      },
      "source": [
        "We can take a look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "2A6byDqlTXJc",
        "outputId": "db2883e7-23d3-450e-8713-597ab8f94623"
      },
      "source": [
        "# we can see \n",
        "df = pd.read_csv(\"toxic_comments.csv\")\n",
        "df.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "5  00025465d4725e87  ...             0\n",
              "6  0002bcb3da6cb337  ...             0\n",
              "7  00031b1e95af7921  ...             0\n",
              "8  00037261f536c51d  ...             0\n",
              "9  00040093b2687caa  ...             0\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTK0H8CNVRTQ"
      },
      "source": [
        "As we can see, we have comments from YouTube videos where most are clean comments, but there are some bad comments that are labeled as either: toxic,\tsevere_toxic,\tobscene,\tthreat,\tinsult and/or\tidentity_hate. We will bunch them all together into the same label we will call 'labels' because Snorkel prefers this.\n",
        "\n",
        "## Preprocessing\n",
        "\n",
        "Let's have a look at the dataset before we start creating labeling functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYYa2QnxXANz",
        "outputId": "815ab448-967f-490f-f5d2-5df689ad9b61"
      },
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.05)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((151592, 8), (7979, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "1pVa6aGgTzX9",
        "outputId": "3868cda0-84d8-4cda-c638-3d2a0a541a66"
      },
      "source": [
        "LABEL_COLUMNS = df.columns.tolist()[2:]\n",
        "df[LABEL_COLUMNS].sum().sort_values().plot(kind=\"barh\");"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4GdLAd5YkSJ"
      },
      "source": [
        "Now, let's add them all up together and compare them to the number of clean comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "6UWBm5cFXqE7",
        "outputId": "e93ab915-155d-4689-9576-c83e9d8d0338"
      },
      "source": [
        "train_toxic = train_df[train_df[LABEL_COLUMNS].sum(axis=1) > 0]\n",
        "train_clean = train_df[train_df[LABEL_COLUMNS].sum(axis=1) == 0]\n",
        "\n",
        "pd.DataFrame(dict(\n",
        "  toxic=[len(train_toxic)], \n",
        "  clean=[len(train_clean)]\n",
        ")).plot(kind='barh');"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD4CAYAAAD4k815AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPT0lEQVR4nO3df2yVVZ7H8c/XUtvtiPwoyiI122I2EwGtIMga5UcI7IBMNPzRCDE6LLtBZf2x68qmLomphkSGqcmIOy6O60zQ4AxTnXVWF0N2hzWuMfJroQJjWVuBnYssQg0srikWe/aPe1puKz/a2+feW759v5KG555z73m+z3luP709z73FQggCAPhxWaELAAAki2AHAGcIdgBwhmAHAGcIdgBwZkjSA44aNSpUVlYmPSwAuLZz587jIYSrkhgr8WCvrKzUjh07kh4WAFwzs0NJjcVSDAA4Q7ADgDMEOwA4k/gaOwD0Rnt7u1KplNra2gpdSl6VlpaqoqJCxcXFOdsHwQ6gIFKplIYOHarKykqZWaHLyYsQglpbW5VKpVRVVZWz/bAUA6Ag2traVF5ePmhCXZLMTOXl5Tn/LYVgB1AwgynUO+XjmAl2AHCGNXYAA0Jl7b8kOt7B1Qsu2H/ixAm99tprWr58eZ/HXrduncrKynTfffdlW15O8YodwKB04sQJvfDCC1k99oEHHhiwoS4R7AAGqdraWrW0tOimm27SihUrtGLFCk2cOFE33HCDNm7cKEl69NFH9fTTT0uSNm/erBkzZqijo0N1dXWqr6+XJDU3N2vOnDmqrq7W5MmT1dLSUrBj6sRSDIBBafXq1dq7d692796tN954Q+vWrVNjY6OOHz+uqVOnasaMGXrmmWc0depUTZ8+XY888og2bdqkyy7r/nr4nnvuUW1trRYuXKi2tjZ1dHQU6IjO4hU7gEHv/fff1+LFi1VUVKTRo0dr5syZ2r59u8rKyvTSSy9p7ty5euihh3Tdddd1e9ypU6d0+PBhLVy4UFL6w0dlZWWFOIRuCHYAuIA9e/aovLxcn332WaFL6TWCHcCgNHToUJ06dUqSNH36dG3cuFHffPONjh07pvfee0+33HKLDh06pGeffVa7du3SO++8o61bt35rjIqKCr355puSpNOnT+urr77K+7H0xBo7gAHhYm9PTFp5ebluu+02TZw4UfPnz9eNN96o6upqmZnWrFmj0aNHa+7cuaqvr9c111yjl19+WUuWLNH27du7jfPqq6/q/vvv15NPPqni4mI1NDRo3LhxeT2WniyEkOiAU6ZMCfxHGwAu5uOPP9b1119f6DIK4lzHbmY7QwhTkhifpRgAcIZgBwBnCHYAcIZgBwBnCHYAcIZgBwBneB87gIGhbljC453M7mF1dbriiiv0+OOPJ1tPHvGKHQCcIdgBDGqvvPJK16dO77333m59LS0tmjdvnm6++WZNnz5dTU1NkqS33npL06ZN06RJkzRnzhwdPXpUUvrV/tKlSzVr1iyNGzdOa9euzfvxSAQ7gEFs3759WrVqlbZs2aLGxkY999xz3fqXLVum559/Xjt37lR9fX3X/7Z0++2368MPP9SuXbu0aNEirVmzpusxTU1N2rx5s7Zt26annnpK7e3teT0miTV2AIPYli1bVFNTo1GjRkmSRo4c2dX35Zdf6oMPPlBNTU1X2+nTpyVJqVRKd999t44cOaKvv/5aVVVVXfdZsGCBSkpKVFJSoquvvlpHjx5VRUVFno4ojWAHgHPo6OjQ8OHDtXv37m/1Pfzww3rsscd055136t1331VdXV1XX0lJSdd2UVGRzpw5k49yu2EpBsCgNXv2bDU0NKi1tVWS9MUXX3T1XXnllaqqqlJDQ4MkKYSgxsZGSdLJkyc1duxYSdL69evzXPXF8YodwMCQ5dsT+2PChAlauXKlZs6cqaKiIk2aNEmVlZVd/Rs2bNCDDz6oVatWqb29XYsWLVJ1dbXq6upUU1OjESNGaPbs2Tpw4EDea78Q/mwvgILgz/byZ3sBAL1EsAOAMwQ7gIJJein4UpCPYybYARREaWmpWltbB1W4hxDU2tqq0tLSnO6Hd8UAKIiKigqlUikdO3as0KXkVWlpac4/sESwAyiI4uLibp/YRHJYigEAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZ5L/e+yf7ZLqhiU+LAAMaHUnC11BF16xA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAOEOwA4AzBDsAONOrYDezeWa238yazaw210UBALJ30WA3syJJP5E0X9J4SYvNbHyuCwMAZKc3r9hvkdQcQvg0hPC1pF9Kuiu3ZQEAsjWkF/cZK+n3GbdTkqZl3sHMlklaJklFV16lyrafJ1ZgEg6uXlDoEgAgbxK5eBpC+GkIYUoIYUpR2bAkhgQAZKk3wX5Y0rUZtytiGwBgAOpNsG+X9MdmVmVml0taJOmfc1sWACBbF11jDyGcMbOHJG2WVCTpZyGEfTmvDACQld5cPFUIYZOkTTmuBQCQAD55CgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4AzBDgDOEOwA4MyQpAe8Yeww7Vi9IOlhAQC9xCt2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZwh2AHCGYAcAZyyEkOyAZqck7U900PwZJel4oYvIErUXBrUXxqVa+4Xq/qMQwlVJ7GRIEoP0sD+EMCUH4+acme2g9vyj9sKg9vzLV90sxQCAMwQ7ADiTi2D/aQ7GzBdqLwxqLwxqz7+81J34xVMAQGGxFAMAzhDsAOBMosFuZvPMbL+ZNZtZbZJj96GGa83s383sd2a2z8weje0jzexfzeyT+O+I2G5mtjbW/JGZTc4Y6wfx/p+Y2Q8y2m82sz3xMWvNzBI+hiIz22Vmb8fbVWa2Ne5vo5ldHttL4u3m2F+ZMcYTsX2/mX0voz1n58jMhpvZ62bWZGYfm9mtl8q8m9lfx+fLXjP7hZmVDtR5N7OfmdnnZrY3oy3n83y+fSRQ+4/ic+YjM/snMxue0den+czmnPWn9oy+vzGzYGaj4u3CznsIIZEvSUWSWiSNk3S5pEZJ45Mavw91jJE0OW4PlfRfksZLWiOpNrbXSvph3L5D0juSTNKfSNoa20dK+jT+OyJuj4h92+J9LT52fsLH8Jik1yS9HW//StKiuL1O0oNxe7mkdXF7kaSNcXt8nP8SSVXxvBTl+hxJWi/pL+L25ZKGXwrzLmmspAOS/iBjvpcM1HmXNEPSZEl7M9pyPs/n20cCtf+ppCFx+4cZtfd5Pvt6zvpbe2y/VtJmSYckjRoI855kGN0qaXPG7SckPZHU+P2o6zeS5ir9adgxsW2M0h+kkqQXJS3OuP/+2L9Y0osZ7S/GtjGSmjLau90vgXorJP1W0mxJb8eTfDzjid81z/HJdGvcHhLvZz3nvvN+uTxHkoYpHY7Wo33Az7vSwf77+M02JM779wbyvEuqVPdwzPk8n28f/a29R99CSRvONU8Xm89svleSqF3S65KqJR3U2WAv6LwnuRTT+c3RKRXbCib+ujVJ0lZJo0MIR2LX/0gaHbfPV/eF2lPnaE/KjyX9raSOeLtc0okQwplz7K+rxth/Mt6/r8eUhCpJxyT93NLLSP9oZt/RJTDvIYTDkuol/bekI0rP405dGvPeKR/zfL59JGmp0q9WdZEaz9WezfdKv5jZXZIOhxAae3QVdN7dXjw1syskvSHpr0II/5vZF9I/+gbc+zzN7PuSPg8h7Cx0LVkYovSvqf8QQpgk6f+U/rWxywCe9xGS7lL6h9M1kr4jaV5Bi+qHfMxzLvZhZislnZG0Iclxc8XMyiT9naQn87XP3s57ksF+WOm1pk4VsS3vzKxY6VDfEEL4dWw+amZjYv8YSZ/H9vPVfaH2inO0J+E2SXea2UFJv1R6OeY5ScPNrPPv+mTur6vG2D9MUmsWx5SElKRUCGFrvP260kF/Kcz7HEkHQgjHQgjtkn6t9Lm4FOa9Uz7m+Xz76DczWyLp+5LuieGVTe2t6vs564/rlH4x0Bi/Zysk/aeZ/WEWtSc77/1Z5+uxzjRE6QsBVTp7QWNCUuP3oQ6T9IqkH/do/5G6X4BYE7cXqPtFjm2xfaTSa8Yj4tcBSSNjX8+LHHfk4Dhm6ezF0wZ1vyC0PG7/pbpfEPpV3J6g7hedPlX6glNOz5Gk/5D03bhdF+d8wM+7pGmS9kkqi2Ovl/TwQJ53fXuNPefzfL59JFD7PEm/k3RVj/v1eT77es76W3uPvoM6u8Ze0HlPOozuUPpdKC2SViY5dh9quF3pX1U+krQ7ft2h9HrabyV9IunfMibTJP0k1rxH0pSMsZZKao5ff5bRPkXS3viYv1cWF2F6cRyzdDbYx8WT3hyfuCWxvTTebo794zIevzLWt18Z7x7J5TmSdJOkHXHu34xP3Eti3iU9Jakpjv+q0mEyIOdd0i+UvhbQrvRvSn+ej3k+3z4SqL1Z6XXnzu/XddnOZzbnrD+19+g/qLPBXtB5508KAIAzbi+eAsBgRbADgDMEOwA4Q7ADgDMEOwA4Q7ADgDMEOwA48/8+OA5OSgjXCwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5QCR81TXN2i"
      },
      "source": [
        "The bad examples are imbalanced, but we will not worry about that. What we will do, however, is to eliminate clean examples from the dataset in order to make it more balanced. We will simply reduce the number of clean comments to a number that is comparable to the toxic comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW-ON3kbXGFF",
        "outputId": "87be6491-9f22-4dea-c459-6aef58a1a702"
      },
      "source": [
        "train_df = pd.concat([\n",
        "  train_toxic,\n",
        "  train_clean.sample(15_000)\n",
        "])\n",
        "\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30463, 8), (7979, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQUFQ-KcZdHR"
      },
      "source": [
        "### Merging All Toxic Comments Together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LcvkhHKEahQ-",
        "outputId": "f550bcb3-55c3-4069-dd03-9eb77566b37f"
      },
      "source": [
        "train_df['labels'] = np.where(train_df[LABEL_COLUMNS].sum(axis=1) == 0, 0, 1)\n",
        "val_df['labels'] = np.where(val_df[LABEL_COLUMNS].sum(axis=1) == 0, 0, 1)\n",
        "train_df.tail()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27174</th>\n",
              "      <td>47e41c90d46dda5d</td>\n",
              "      <td>\"\\n\\nProposed move to Social Darwinism\\nHaving discussed the point here, there seems to be no reason not to move the page back to Social Darwinism to comply with the Wikipedia:Manual of Style (capital letters)#Religions, deities, philosophies, doctrines and their adherents section which concludes that \"\"Philosophies, theories, doctrines, and systems of thought do not begin with a capital letter, unless the name derives from a proper noun:\"\". As Darwinism derives from the proper noun \"\"Darwin\"\" it should always begin with a capital letter, thus Social Darwinism is correct. Anyone differ from this assessment? .. , talk \"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93187</th>\n",
              "      <td>f92ad99ccff7ce2d</td>\n",
              "      <td>In 1952 Ragual Samuel Rahator published Christology and Krishnology, a Critical Study, through Northwestern University.Christology and Krishnology, a Critical Study Northwestern University</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131918</th>\n",
              "      <td>c1e606856701121a</td>\n",
              "      <td>The comment about the horns was just a joke.  I was just emphasizing how this article has a lot of weasel words in it that are more opinion than fact.\\n\\nRamdrake is shooting down everything I argue about.  I'm obviously not the only person who has issues with this article.  I don't see why we can't make it longer and include all of rushton's theories while also leaving plenty of room for critics.  \\n\\nI think we should open this article up.  I mean it's better if the article is twice as long and has his theories, critiques, and everything.  Then everyone will be happy, but as the article stands it is just not very good.  Ramdrake seems to want to have an article only on criticism, but there are many other people who would contribute more.  Let's allow them to do it.  I mean the article is fairly short as it is.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147913</th>\n",
              "      <td>43a691685854396c</td>\n",
              "      <td>You are no fun. I give up. But the edits will still remain there as my proof that I have won the war of truths against Wikipedia. 218.186.13.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138974</th>\n",
              "      <td>e7be8d938a2c803f</td>\n",
              "      <td>Notice\\n\\nYour attacks on Wikipedia:Suspected_sock_puppets are considered vandalism.  The fact that, for the two years ending last Sunday, the account  was almost entirely inactive, its only contributions being changes in spelling, pruning of video-game weapon descriptions, and racial invective, makes it suspect as a part-time puppet account, or perhaps an artificially-aged shell-identity.  In the past week, it has made nearly as many edits as it had since its inception some years ago.  What's more, these have caused considerable disruption in the community.  I have seen this pattern of behaviour before in destructive users who are trying either to deflect guilt and reprisal from yourself onto other Wikipedians, or to make a name for a vandalism-only account by artlessly effecting a major change, such as an article deletion or a user block.\\n\\nBe warned that your actions have not gone unnoticed.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ... labels\n",
              "27174   47e41c90d46dda5d  ...      0\n",
              "93187   f92ad99ccff7ce2d  ...      0\n",
              "131918  c1e606856701121a  ...      0\n",
              "147913  43a691685854396c  ...      0\n",
              "138974  e7be8d938a2c803f  ...      0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "0RSSiN0BcPU8",
        "outputId": "c10e3e39-be17-4b81-9755-3cb8726700e4"
      },
      "source": [
        "train_df = train_df.drop(LABEL_COLUMNS, axis=1)\n",
        "val_df = val_df.drop(LABEL_COLUMNS, axis=1)\n",
        "train_df"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134827</th>\n",
              "      <td>d11ceb3723d263bc</td>\n",
              "      <td>Blah Blah Blah. Cry me a river. Go suck a prick.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123055</th>\n",
              "      <td>9240c1fb4e5caf01</td>\n",
              "      <td>\"::So Hersford gets away with this?  Because I stand up to this moral choice, I get fucked over with two or three warnings on my page?  Instead someone doesn't warn Hersford for his bad choice?  Please note his long excuse filled statement on his page.  Does that not read like an attack on me?  I don't like to be attacked, and he was caught for a big mistake, so instead of immediately reconsidering his mistake, he went on the attack.  An age-old public relations ploy, which I don't buy.  Hersford may or may not be a racist, but he certainly let an avowed racist get away with something.  Sad.   Talk• Contributions \\n\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37107</th>\n",
              "      <td>630c54de93671c68</td>\n",
              "      <td>\"\\n\\nI JUST GAVE PROOF THEY ARE OK AND YOU BLEW ME THE HELL OFF. You are annoying me. I gave plenty of proof and you reply with an \"\"they are fan sites. fan sites are bad\"\" answer. It is oh. so. amazing how ignored me completely.     JUSTICE IS SERVED! \"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12861</th>\n",
              "      <td>2215d63992760558</td>\n",
              "      <td>NOT REALLY, GO AHEAD AND FUCK OFF BITCH!!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64710</th>\n",
              "      <td>ad2e69231dd81818</td>\n",
              "      <td>who are you \\n\\nfuck?? 182.16.240.42</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27174</th>\n",
              "      <td>47e41c90d46dda5d</td>\n",
              "      <td>\"\\n\\nProposed move to Social Darwinism\\nHaving discussed the point here, there seems to be no reason not to move the page back to Social Darwinism to comply with the Wikipedia:Manual of Style (capital letters)#Religions, deities, philosophies, doctrines and their adherents section which concludes that \"\"Philosophies, theories, doctrines, and systems of thought do not begin with a capital letter, unless the name derives from a proper noun:\"\". As Darwinism derives from the proper noun \"\"Darwin\"\" it should always begin with a capital letter, thus Social Darwinism is correct. Anyone differ from this assessment? .. , talk \"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93187</th>\n",
              "      <td>f92ad99ccff7ce2d</td>\n",
              "      <td>In 1952 Ragual Samuel Rahator published Christology and Krishnology, a Critical Study, through Northwestern University.Christology and Krishnology, a Critical Study Northwestern University</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131918</th>\n",
              "      <td>c1e606856701121a</td>\n",
              "      <td>The comment about the horns was just a joke.  I was just emphasizing how this article has a lot of weasel words in it that are more opinion than fact.\\n\\nRamdrake is shooting down everything I argue about.  I'm obviously not the only person who has issues with this article.  I don't see why we can't make it longer and include all of rushton's theories while also leaving plenty of room for critics.  \\n\\nI think we should open this article up.  I mean it's better if the article is twice as long and has his theories, critiques, and everything.  Then everyone will be happy, but as the article stands it is just not very good.  Ramdrake seems to want to have an article only on criticism, but there are many other people who would contribute more.  Let's allow them to do it.  I mean the article is fairly short as it is.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147913</th>\n",
              "      <td>43a691685854396c</td>\n",
              "      <td>You are no fun. I give up. But the edits will still remain there as my proof that I have won the war of truths against Wikipedia. 218.186.13.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138974</th>\n",
              "      <td>e7be8d938a2c803f</td>\n",
              "      <td>Notice\\n\\nYour attacks on Wikipedia:Suspected_sock_puppets are considered vandalism.  The fact that, for the two years ending last Sunday, the account  was almost entirely inactive, its only contributions being changes in spelling, pruning of video-game weapon descriptions, and racial invective, makes it suspect as a part-time puppet account, or perhaps an artificially-aged shell-identity.  In the past week, it has made nearly as many edits as it had since its inception some years ago.  What's more, these have caused considerable disruption in the community.  I have seen this pattern of behaviour before in destructive users who are trying either to deflect guilt and reprisal from yourself onto other Wikipedians, or to make a name for a vandalism-only account by artlessly effecting a major change, such as an article deletion or a user block.\\n\\nBe warned that your actions have not gone unnoticed.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30463 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ... labels\n",
              "134827  d11ceb3723d263bc  ...      1\n",
              "123055  9240c1fb4e5caf01  ...      1\n",
              "37107   630c54de93671c68  ...      1\n",
              "12861   2215d63992760558  ...      1\n",
              "64710   ad2e69231dd81818  ...      1\n",
              "...                  ...  ...    ...\n",
              "27174   47e41c90d46dda5d  ...      0\n",
              "93187   f92ad99ccff7ce2d  ...      0\n",
              "131918  c1e606856701121a  ...      0\n",
              "147913  43a691685854396c  ...      0\n",
              "138974  e7be8d938a2c803f  ...      0\n",
              "\n",
              "[30463 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wANMvHnJZBRc"
      },
      "source": [
        "## Preparing the Data for Snorkel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "nyCd-Ye3YtJf",
        "outputId": "0d6def12-8a92-4fab-8a80-f2b02b2b78aa"
      },
      "source": [
        "train_df = train_df.rename(columns={\"comment_text\": \"text\"})\n",
        "val_df = val_df.rename(columns={\"comment_text\": \"text\"})\n",
        "val_df.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>155376</th>\n",
              "      <td>bcd794ddc143f4a1</td>\n",
              "      <td>(UTC)\\n\\nI wholeheartedly disagree. If you choose to annotate things using the Christian calendar, then AD should be the default. CE and BCE are and affront to the people whose calendar you're using. Use another calendar if you don't want to use the proper notation.   21:03, 11 March 2014</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72551</th>\n",
              "      <td>c2252b14e80ca744</td>\n",
              "      <td>Hello, please refrain from pushing your views on Wikipedia. I understand that you identify strongly with and support the values of the former illegal state: The Confederate States of America which was founded on the principals of racism and slavery. Since these are extremist and reactionary positions in our modern society, I recommend you think carefully about whether your contributions truly advance the goals of Wikipedia. Thank you.\\n\\nBest,\\n\\nAnonWikiCitizen</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112660</th>\n",
              "      <td>5ab4d9dd112bcf08</td>\n",
              "      <td>This is not an article about scholarship on the Cold War, but an article about the Cold War itself; scholarship of all sorts, traditional or not, should be allowed if reliable and germain.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115119</th>\n",
              "      <td>6786b6599e32031f</td>\n",
              "      <td>\"The problem with saying that Warren G. Harding was the first African-American President is that it is a theory that is unproven by fact.  While many people believe this concept - some even go to great lengths to self publish books on the topics, there is no way to scientifically prove the concept, nor is there any way to verify generally accepted documents that could show this is even a possibility.  The rumor that Harding was black rages about based on two quotes, one by Harding himself (where he says he doesn't know if it could be true, the other a rumor started by his future father-in-law meant to destroy Harding's business and reputation.) Consider verifiable these FACTS on the matter:\\n1) Harding's alleged \"\"black\"\" lineage can not be proven through United States Census forms, death certificate, or any other PRIMARY SOURCE document.  As far back as the 1850 census (the first to name all people enumerated, and designate their race) Harding's father and mother are enumerated as white.  This is most frequently dismissed by Harding Conspiracy followers who claim the census forms were doctored after the fact as part of a Federal Government cover-up.\\n\\n2) There is no DNA proof of Harding's alleged \"\"black blood\"\", (nor is there proof that Harding fathered Elizabeth Ann Christian).\\n\\n3) Harding was not raised as a cultural \"\"black\"\" that is to say that he was not raised within the black community, and therefore would have not had the same cultural experiences that other blacks in the era would have had.\\n\\n4) \"\"Black Harding\"\" promoters will point to William Estabrook Chancellor's book on Harding as proof of government conspiracy.  And it is interesting how swifty the government worked to squash the book and get its copies.  But if one looks at Chancellor's research methodology (and we step away from those who claim that the book was supressed) - all of it based on hearsay - any student in college today who would present this type of research in the form of a paper, masters thesis or dissertation would have been thrown out of college for faulty research!   \\n\\n5) Some of the promoters of this theory of Harding's \"\"blackness\"\" on \"\"family stories\"\".  While folklore is not always untrue, folklore can be embellished from storyteller to storyteller. Ask anyone who studies it, folklore is at the mercy of the one who passes it on.\\n\\n6) The promoters of these theories go to great lengths to attack the people who poke logical holes in their wishful arguments. They can not refute the facts, so they attack the people who question their beliefs. Take a look at the \"\"reviews\"\" of Harding books published in the past ten years in places like Amazon and B&amp;N; online and you'll get an idea how some people will attack those who do not buy into the black \"\"Black Harding\"\" myth.\\n\\nIf Wikipedia were to add information that Harding was the first black President, without irrfetable proof, it simply ads another chain in the long list of unrliable misinformation.   \\n\\n\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67586</th>\n",
              "      <td>b4de886da6ee092e</td>\n",
              "      <td>\"\\n\\n Pasttimes \\n\\nYou could say \"\"I'm onto you\"\", but I don't think that would convey an appropriate tone for how I really feel. Let me put it this way:\\n\\nI KNOW EXACTLY WHAT YOU GET UP TO IN YOUR SPARE TIME..........but I like it! Your \"\"secrets\"\" are safe with me, have no fear. 79.75.171.154  \"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ... labels\n",
              "155376  bcd794ddc143f4a1  ...      0\n",
              "72551   c2252b14e80ca744  ...      0\n",
              "112660  5ab4d9dd112bcf08  ...      0\n",
              "115119  6786b6599e32031f  ...      0\n",
              "67586   b4de886da6ee092e  ...      0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNOfniQnfctT"
      },
      "source": [
        "## Writing Labeling Functions (LFs)\n",
        "\n",
        "For clarity, we define constants to represent the class labels for non-toxic, toxic, and abstaining. These will go into our labeling functions so that the constants feed into the labeling process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tuwA_CNZZOh"
      },
      "source": [
        "ABSTAIN = -1\n",
        "NONTOXIC = 0\n",
        "TOXIC = 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jeEoNwvfpz-"
      },
      "source": [
        "# Useful for looking at the data and creating the labeling functions\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', 200)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skrXRkAKgg88"
      },
      "source": [
        "Let's at a sample of the dataset so that we can come up with labeling functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XpTSYGRdgYf6",
        "outputId": "0f40eaeb-127c-4fe7-e888-59d93019a4ae"
      },
      "source": [
        "train_df[train_df['labels'] == 1].sample(50, random_state=42)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23005</th>\n",
              "      <td>3cceebb6c52454bb</td>\n",
              "      <td>George, why did you come here to tell such lies ?????\\n202.92.40.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14349</th>\n",
              "      <td>25eb9145e95be68e</td>\n",
              "      <td>Ignore him, Scientizzle is just an asshole.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117468</th>\n",
              "      <td>73a3efe15fefcdbc</td>\n",
              "      <td>Do you give blowjob discounts to wikipedia members?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125202</th>\n",
              "      <td>9da308e33d31e93e</td>\n",
              "      <td>Okay there stupid. \\n\\nSee those words there in brackets.\\n\\nThose are the source.\\n\\nSee that, there is a little reference (TORAH, TANAKH). for you. It's online! I'm gathering the rest. So just chillax with your impetuous stupidity.\\n\\nI even spelled out the chapter, and the verse for you. EVEN GAVE THE BOOK(S) THEY WERE CONTAINED IN.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121626</th>\n",
              "      <td>8abf6aec0a13bcf9</td>\n",
              "      <td>Audi A4\\nYOU ARE ASSHOLE, MOTHERFUCKER, SHIT, FUCK, ASSHOLE. (talk • contributions)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71551</th>\n",
              "      <td>bf8b1e93498277af</td>\n",
              "      <td>stupid sit i will behead you</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78727</th>\n",
              "      <td>d29ea4ec66b1b882</td>\n",
              "      <td>And why the fuck should i care? \\n\\n67.165.71.214</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122226</th>\n",
              "      <td>8dd9ff726e894b47</td>\n",
              "      <td>how dare u you german piece of dog shit \\n\\ndont u fucking clear my edit ever again u piece of horse shit faggot</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51115</th>\n",
              "      <td>88bcdab667d66d10</td>\n",
              "      <td>User:abd is Muslim Scum</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23695</th>\n",
              "      <td>3e97450e9f97f1d3</td>\n",
              "      <td>In general, I'm sick of your obnoxious excuses and immature piling-up. This will be all. — | talk</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1543</th>\n",
              "      <td>04273b9c5738c89c</td>\n",
              "      <td>hi \\n\\nhi there... this may sound a bit stupid question but dont get it wrong. are you Jew? if so how are you really thinking there is any resemplence between holocoust and Armeian deportations?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23399</th>\n",
              "      <td>3dcbbb9a6cb720d3</td>\n",
              "      <td>fuck  \\n\\nyou son of a bitch your sıde make us creasy fuck you and your sıde</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147358</th>\n",
              "      <td>3b31f423ac1946b4</td>\n",
              "      <td>Whoever used 'she' instead of neutral they is a little p ussy fa ggot. I'm going to change it to HE</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128922</th>\n",
              "      <td>b17307ef8cd39186</td>\n",
              "      <td>REDIRECT Talk:Fuck the Industry</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84790</th>\n",
              "      <td>e2e48d76d1b6cf5a</td>\n",
              "      <td>Ja, final warnings. Lived with 'em for decades. You're like the Rainbow Likudis at the Pentagon. Go get a colonoscopy. Your crap stinks.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20108</th>\n",
              "      <td>35208aad341d617b</td>\n",
              "      <td>He is very much right, the world has woken up to you. You are nothing more then a two-bit huckster perpetrating a giant fraud, give my regards to the boys at East Anglia.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121720</th>\n",
              "      <td>8b330ba7262e8448</td>\n",
              "      <td>THE ACLU IS ON YOUR ASS! \\n\\nThis latino will never get up until everyone of you racist WiKKKipedia gringos are behind bars!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150636</th>\n",
              "      <td>6f5cff823a1a9938</td>\n",
              "      <td>Yea? Well FUCK YOU! 75.30.246.159</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147064</th>\n",
              "      <td>364b6c24210e2345</td>\n",
              "      <td>Fuck you you fucking pig!\\n\\nYou motherfucking pig.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22168</th>\n",
              "      <td>3a77c5ec00474a23</td>\n",
              "      <td>HAHAHAH who did they rape? Please if you give me ONE case were a mujjahedin raped someone(they ain´t Serb soldiers you know) I´l send you a million dollars. Who did they kill? Enemy soldiers they were cases of civilan cassualtis but this isn´t a charateristic for Mujjahedins. They helped there Muslim brothers nothing wrong with that YOU should lay of propaganda. And I´m upset Santa isn´t real I´m not gonna wright it in wikipedia.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125022</th>\n",
              "      <td>9ccd8378745a2c5e</td>\n",
              "      <td>i suggest my balls in yer mouth - no page no reference  82.209.225.33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73703</th>\n",
              "      <td>c53d8d5abaada677</td>\n",
              "      <td>You stupid, you are so damn follish. And the BMT Broadway Line page, when the north tracks of the Manhattan Bridge reopen on February 2004, the N trains was express and the W was local, but you switch it the opposite way. YOU IDIOT! Read the History site on the BMT Broadway Line page and find out.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11765</th>\n",
              "      <td>1f1abb0e6ddac0bc</td>\n",
              "      <td>FAKE BLOCKING \\n\\nEARLIER THAT BLOCK WAS FAKE IF YOU KNOW SO MUCH CAN YOU PLEASE STOP TOUCHING MY STUFF OR I AM GOING TO NEVER GET ON WIKIPEDIA EVER AGAIN I AM GOING TO CALL YOU GAY 10 TIMES A DAY NNNNNNNNNNNNNNNNNNNNNNNNNNIIIIIIIIIIIIIIIIIIIIIGGGGGGGGGGGGGGGGGGGGGGGGAAAAAAAAAAAAAAAAAAAAA.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24377</th>\n",
              "      <td>405ed4e56f1a71a4</td>\n",
              "      <td>Hello Jakeyboy! \\n\\nIt is I the almighty lord and master of the universe. My protege EvilAmeoba has brought it to my attention that you have not been very nice. Bad Jakeyboy! I should punish you to HELL!!! I hearby order you to apologise immediately!!! Her page did not need to be deleted. You of all people should know about free speech. Before I go I would just like to say Fuck you Jakeyboy!!!\\n\\nI HAVE SPOKEN!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10406</th>\n",
              "      <td>1b7fe21f6b20f176</td>\n",
              "      <td>The Wack Pack \\n\\nYou're fucking insane and drunk with power. Instead of totally removing big Howard Stern guys like Crackhead Bob and Fred the Elephant Boy, why not just remove the parts that your majesty finds offensive?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122793</th>\n",
              "      <td>90dc003bbf58e060</td>\n",
              "      <td>is it because it is of my naked mum having sex with me? i am indeed a faggot who sucks his dads cock. fucking homo. go fucking die you piece of shit</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151362</th>\n",
              "      <td>7bd908b4b4bda3c2</td>\n",
              "      <td>fuck u u stupid fagget block me i dare u</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106730</th>\n",
              "      <td>3ad2ac1502a5b739</td>\n",
              "      <td>FUCK YOU! the source is the top 100 LOWEST ACCEPTANCE RATES. In what world is that not a source you asshole!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1559</th>\n",
              "      <td>04316638593290c8</td>\n",
              "      <td>I'm the one that went to get help from the admin incident board because he was edit warring with me. Why would I call the police if I'm the one that committed the crime? You truly are ridiculous. Basically that guy stole my wallet, I punched him, and you're arresting me for assault. Horrible power hungry ego boosters have taken over wikipedia it seems.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157062</th>\n",
              "      <td>d7ccd3a9b912bc67</td>\n",
              "      <td>I AM TRYING SO HARD NOT TO LOOSE MY TEMPER SARAH\\n\\nSTOP DELETING THE CATEGORY OF WHOVIANS\\n\\nWHY DO YOU KEEP DELETING IT\\n\\nWHY\\n\\nWHY\\n\\nWHY</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102815</th>\n",
              "      <td>262f7d89eb8384a8</td>\n",
              "      <td>STFU and kiss my asshole</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57735</th>\n",
              "      <td>9a80014f084ce26b</td>\n",
              "      <td>\"\\n\\n I suppose him calling me a jerk was just a \"\"natural\"\" reaction no ?   \"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52936</th>\n",
              "      <td>8d7c7f19c82528ac</td>\n",
              "      <td>Hey UW Dawgs \\n\\nDude, why did you delete my comment about the oregon ducks beating the Washington Huskies? The Huskies suck, and get crushed by the ducks every year. You should be absolutely ashamed of deleting that. Oh well, I guess it's just another butthurt huskies fan. Your team is bad and you should feel bad. Keep calm and keep on sucking huskies.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126980</th>\n",
              "      <td>a7173679cb9219c8</td>\n",
              "      <td>Stop to be a crybaby. You messed the article with wrong information. Fix it. This is not Brazil.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97751</th>\n",
              "      <td>0af1f50e21918730</td>\n",
              "      <td>Great, some furfag is undoing my quality opsts. Fuck you!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104511</th>\n",
              "      <td>2f1f2519c3b9a948</td>\n",
              "      <td>Oh go cuck yourself. Protecting fake users.  Coward. Fuck you166.205.139.210</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12745</th>\n",
              "      <td>21d21e47a639aa9e</td>\n",
              "      <td>Hi\\n\\nwhy did you give User:Barneca a kindness star. he's the rudest admin i have ever met on here. A truly nasty piece of work and many people agree with me</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96256</th>\n",
              "      <td>02d3b74a4e7a7183</td>\n",
              "      <td>\"\\n\\n DILDO! \\n\\nJust so we're on the same page then, you're less of a man.  The Marine Corps should've been DISBANDED COMPLETELY after World War II.  We do the exact same thing the Army does, and act like we're hardasses, which clearly by you taking offense to a comment posted on the internet, is not the case.  Go back to your air-conditioned office and push my DD214 thru you fucking POG.  And MCMAP, once again, I've seen better karate skills by 7 year olds in a FREE class at the YMCA.  I'm sorry I'm not acting like a gentleman on a web based encyclopedia edited by nerds sitting in the internet center in Kuwait.  I'm glad that you're collecting combat pay to sit over in Kuwait (or Al Asad because apparently there's a war still going on at THAT base that I didn't know about) on your \"\"combat deployment\"\" to edit wikipedia on your NIPR net that you have running straight to your 2 man air conditioned room.  I bet you feel real fucking proud that you collect the same amount of pay as the ones doing the hard work like the grunts.  Rest assured knowing that you weren't man enough to take on a real job in the Marine Corps.  Sleep tight knowing that some poor fucking boot Lance 03 is on fucking post for you 6 on 6 off so your fucking POG ass doesn't have to.\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54283</th>\n",
              "      <td>910679c3a909108c</td>\n",
              "      <td>I am not aware of wikipedia guidelines regarding poopie pants, though I'm pretty sure there is at least implicit consensus that having them is not good.  I am also pretty sure that somehow your pants, physically, spiritually or metaphorically are full of poop. The only reason that you consider comments like this to be personal attacks is because your pants are so woefully full of poop (in one of the aforementioned modalities).  Your contributions to , Benzodiazepines and poop (which may lead you to pages with information useful for removing it from your pants). You're not the boss of me.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132937</th>\n",
              "      <td>c72f106efa7bffcc</td>\n",
              "      <td>Trouted \\n\\nYou have been trouted for: DELETING MY PAGE NOOB. niggaplz</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149635</th>\n",
              "      <td>5f04a07ebb59fa3d</td>\n",
              "      <td>Alansohn tucks his sack back every now and then and tells his gay roommate to call him Sandra.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109241</th>\n",
              "      <td>48320a741bf7b1b3</td>\n",
              "      <td>you edit \\n\\nYOU EDIT IS VANDAL! STOP OR DIE!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123175</th>\n",
              "      <td>92f71277634f281c</td>\n",
              "      <td>Stabby McPenis \\n Stab\\n Stab stab stab</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5793</th>\n",
              "      <td>0f7e619057e7f123</td>\n",
              "      <td>\"\\n\\nUgh, I hate when people add BS to articles like that.... Crap.  ♣   Chat wit' me  §  Contributions ♣ \"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117856</th>\n",
              "      <td>759485f8ffbee6b5</td>\n",
              "      <td>You first. You don't even know what is going on so shut up!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28413</th>\n",
              "      <td>4b3945d021a8af3c</td>\n",
              "      <td>\"\\n\\nThis needed to be clarified since there has been a problem with him inserting subsequent posts ahead of mine, which can be misleading to a reader. When I tried to correct the positions yesterday in another incident, here is what he wrote in his edit summary when he positioned his post ahead of mine again:\\n\\n01:57, 13 May 2010 The Magnificent Clean-keeper (talk | contribs) m (180,836 bytes) (Undid revision 361800511 by Zlykinskyja (talk)Don't fucking move my comments again. This is plain vandalism) (undo)\\n\\nSo when I objected to his use again of the word \"\"fucking\"\" he then used it at me two more times, as reflected above. This follows a prior incident a few weeks ago when he used the word \"\"fucking\"\" at me. I repeatedly objected and asked him not to do that. I think he did this again because he knew it would upset me because of how upset I was about the prior incident. \\n\\nAlso, I have been called by someone else a \"\"bitch\"\" and the words \"\"cunt\"\" and \"\"cock\"\" \"\"shit\"\" have been directed at me on this Talk page. I have repeatedly objected and nothing is done. It is as if women who want to contribute here have to put up with a gauntlet of abuse if they wish to stay here. And no, it isn't unreasonable to object to such disrespectful treatment of women. This is not the 1950s. None of this should be going on.   \"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107938</th>\n",
              "      <td>40f93a6d1792a4d4</td>\n",
              "      <td>Does anyone even know what the hell this song is about?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71956</th>\n",
              "      <td>c0a53df02fd5d288</td>\n",
              "      <td>AGAIN, PHuck U \\nThere is no justice in Wikipedia only Thugocracy.  I am calling to task Nuclear Warfare.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113602</th>\n",
              "      <td>5f710549fa46b5c1</td>\n",
              "      <td>Wikipedia's downfall is that it is free.\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS\\nSO FUCK YOU FOR SUPRESSING THAT YOU FACISTS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79906</th>\n",
              "      <td>d5d53c6d1b608768</td>\n",
              "      <td>\"\\nIf Zarine Khan were Indian, you'd feel very \"\"white\"\" but I am sorry, she is a Pathan(Iranic) and you are still dark skinned Indian.   \"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ... labels\n",
              "23005   3cceebb6c52454bb  ...      1\n",
              "14349   25eb9145e95be68e  ...      1\n",
              "117468  73a3efe15fefcdbc  ...      1\n",
              "125202  9da308e33d31e93e  ...      1\n",
              "121626  8abf6aec0a13bcf9  ...      1\n",
              "71551   bf8b1e93498277af  ...      1\n",
              "78727   d29ea4ec66b1b882  ...      1\n",
              "122226  8dd9ff726e894b47  ...      1\n",
              "51115   88bcdab667d66d10  ...      1\n",
              "23695   3e97450e9f97f1d3  ...      1\n",
              "1543    04273b9c5738c89c  ...      1\n",
              "23399   3dcbbb9a6cb720d3  ...      1\n",
              "147358  3b31f423ac1946b4  ...      1\n",
              "128922  b17307ef8cd39186  ...      1\n",
              "84790   e2e48d76d1b6cf5a  ...      1\n",
              "20108   35208aad341d617b  ...      1\n",
              "121720  8b330ba7262e8448  ...      1\n",
              "150636  6f5cff823a1a9938  ...      1\n",
              "147064  364b6c24210e2345  ...      1\n",
              "22168   3a77c5ec00474a23  ...      1\n",
              "125022  9ccd8378745a2c5e  ...      1\n",
              "73703   c53d8d5abaada677  ...      1\n",
              "11765   1f1abb0e6ddac0bc  ...      1\n",
              "24377   405ed4e56f1a71a4  ...      1\n",
              "10406   1b7fe21f6b20f176  ...      1\n",
              "122793  90dc003bbf58e060  ...      1\n",
              "151362  7bd908b4b4bda3c2  ...      1\n",
              "106730  3ad2ac1502a5b739  ...      1\n",
              "1559    04316638593290c8  ...      1\n",
              "157062  d7ccd3a9b912bc67  ...      1\n",
              "102815  262f7d89eb8384a8  ...      1\n",
              "57735   9a80014f084ce26b  ...      1\n",
              "52936   8d7c7f19c82528ac  ...      1\n",
              "126980  a7173679cb9219c8  ...      1\n",
              "97751   0af1f50e21918730  ...      1\n",
              "104511  2f1f2519c3b9a948  ...      1\n",
              "12745   21d21e47a639aa9e  ...      1\n",
              "96256   02d3b74a4e7a7183  ...      1\n",
              "54283   910679c3a909108c  ...      1\n",
              "132937  c72f106efa7bffcc  ...      1\n",
              "149635  5f04a07ebb59fa3d  ...      1\n",
              "109241  48320a741bf7b1b3  ...      1\n",
              "123175  92f71277634f281c  ...      1\n",
              "5793    0f7e619057e7f123  ...      1\n",
              "117856  759485f8ffbee6b5  ...      1\n",
              "28413   4b3945d021a8af3c  ...      1\n",
              "107938  40f93a6d1792a4d4  ...      1\n",
              "71956   c0a53df02fd5d288  ...      1\n",
              "113602  5f710549fa46b5c1  ...      1\n",
              "79906   d5d53c6d1b608768  ...      1\n",
              "\n",
              "[50 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPzyVv88gzzW",
        "outputId": "0fca5551-4177-4b74-98b7-e29e92105b3d"
      },
      "source": [
        "# Showing the most common words to make the labeling function creation process quicker\n",
        "# This is where we can come up with a custom keyword list\n",
        "\n",
        "pd.Series(' '.join(train_df[train_df['labels'] == 1].sample(50, random_state=42).text).split()).value_counts()[:50]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "the           55\n",
              "YOU           42\n",
              "you           36\n",
              "to            35\n",
              "a             30\n",
              "of            30\n",
              "is            30\n",
              "I             28\n",
              "and           25\n",
              "FUCK          19\n",
              "THAT          19\n",
              "SO            19\n",
              "FOR           17\n",
              "FACISTS       17\n",
              "SUPRESSING    17\n",
              "that          17\n",
              "on            15\n",
              "it            13\n",
              "not           13\n",
              "your          13\n",
              "my            11\n",
              "with          11\n",
              "in            11\n",
              "fucking       11\n",
              "You           10\n",
              "have          10\n",
              "are           10\n",
              "\"              9\n",
              "I'm            9\n",
              "me             9\n",
              "at             8\n",
              "like           8\n",
              "be             8\n",
              "for            7\n",
              "he             7\n",
              "should         7\n",
              "this           7\n",
              "did            7\n",
              "This           7\n",
              "there          7\n",
              "been           6\n",
              "just           6\n",
              "u              6\n",
              "because        6\n",
              "so             6\n",
              "by             6\n",
              "his            6\n",
              "i              6\n",
              "get            5\n",
              "edit           5\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk-vftHWldb3"
      },
      "source": [
        "### Labeling Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UbimMDBhRwX"
      },
      "source": [
        "@nlp_labeling_function()\n",
        "def contains_work_of_art(x):\n",
        "    \"\"\"If comment contains titles of books, songs, etc., label non-toxic, else abstain\"\"\"\n",
        "    if any([ent.label_ == \"WORK_OF_ART\" for ent in x.doc.ents]):\n",
        "        return NONTOXIC\n",
        "    else:\n",
        "        return ABSTAIN\n",
        "    \n",
        "@nlp_labeling_function()\n",
        "def contains_entity(x):\n",
        "    \"\"\"If comment contains least 3 mentions of an entity, label non-toxic, else abstain\"\"\"\n",
        "    if len([ent.label_ in [\"PERSON\", \"GPE\", \"LOC\", \"ORG\", \"LAW\", \"LANGUAGE\"] for ent in x.doc.ents])>2:\n",
        "        return NONTOXIC\n",
        "    else:\n",
        "        return ABSTAIN"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5JpH56dlipy"
      },
      "source": [
        "@preprocessor(memoize=True)\n",
        "def textblob_sentiment(x):\n",
        "    scores = TextBlob(x.text)\n",
        "    x.polarity = scores.sentiment.polarity\n",
        "    x.subjectivity = scores.sentiment.subjectivity\n",
        "    return x\n",
        "\n",
        "@labeling_function(pre=[textblob_sentiment])\n",
        "def textblob_polarity(x):\n",
        "    \"\"\"If comment has a polarity score between +0.9 and +1, label non-toxic, else abstain\"\"\"\n",
        "    return NONTOXIC if x.polarity > 0.9 else ABSTAIN\n",
        "\n",
        "@labeling_function(pre=[textblob_sentiment])\n",
        "def textblob_subjectivity(x):\n",
        "    \"\"\"If comment has a subjectivity score between +0.7 and +1, label non-toxic, else abstain\"\"\"\n",
        "    return NONTOXIC if x.subjectivity >= 0.7 else ABSTAIN"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGY_yIHilmL-"
      },
      "source": [
        "# @labeling_function()\n",
        "# def contains_profanity(x):\n",
        "#     \"\"\"\n",
        "#     If comment contains profanity label toxic, else abstain. \n",
        "#     Profanity determined using this library - https://github.com/snguyenthanh/better_profanity\n",
        "#     \"\"\"\n",
        "#     return TOXIC if profanity.contains_profanity(x.text) else ABSTAIN"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA_hwoDdlyPy"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# @nlp_labeling_function()\n",
        "# def contains_pleaseread(x):\n",
        "#     \"\"\"\n",
        "#     Will match commonly occuring phrases like - \n",
        "#     Please read this\n",
        "#     Please read the\n",
        "#     Please read\n",
        "#     \"\"\"\n",
        "#     matcher = PhraseMatcher(nlp.vocab)\n",
        "#     pattern = [{\"LEMMA\": \"please\"},\n",
        "#                {\"LEMMA\": \"read\"},\n",
        "#                {\"LEMMA\": \"the\", \"OP\": \"?\"},\n",
        "#                {\"LEMMA\": \"this\", \"OP\": \"?\"}]\n",
        "#     matcher.add(\"p1\", None, pattern)\n",
        "#     matches = matcher(x.doc)\n",
        "#     return NONTOXIC if len(matches)>0 else ABSTAIN\n",
        "\n",
        "@nlp_labeling_function()\n",
        "def contains_stopvandalizing(x):\n",
        "    \"\"\"\n",
        "    Will match commonly occuring phrases like - \n",
        "    stop vandalizing\n",
        "    do not vandalize\n",
        "    don't vandalize\n",
        "    \"\"\"\n",
        "    matcher = PhraseMatcher(nlp.vocab)\n",
        "    pattern1 = [\"do not vandalize\", 'vandalize']\n",
        "    pattern2 = [{\"LEMMA\": \"stop\"}, \n",
        "                {\"LEMMA\": \"vandalize\"}]\n",
        "    matcher.add(\"p1\", None, pattern1)\n",
        "    matcher.add(\"p2\", None, pattern2)\n",
        "    matches = matcher(x.doc)\n",
        "    return NONTOXIC if len(matches)>0 else ABSTAIN\n",
        "    \n",
        "# @nlp_labeling_function()\n",
        "# def contains_harassme(x):\n",
        "#     \"\"\"\n",
        "#     Will match commonly occuring phrases like - \n",
        "#     harass me\n",
        "#     harassed me\n",
        "#     harassing me\n",
        "#     \"\"\"\n",
        "#     matcher = Matcher(nlp.vocab)\n",
        "#     pattern = [{\"LOWER\": \"harass\"}, \n",
        "#                {\"LOWER\": \"me\"}]\n",
        "#     matcher.add(\"p1\", None, pattern)\n",
        "#     matches = matcher(x.doc)\n",
        "#     return NONTOXIC if len(matches)>0 else ABSTAIN\n",
        "\n",
        "# @nlp_labeling_function()\n",
        "# def contains_willreport(x):\n",
        "#     \"\"\"Will match commonly observed phrases like - \n",
        "#     report you\n",
        "#     reported you\n",
        "#     reporting you\n",
        "#     reported your\n",
        "#     \"\"\"\n",
        "#     matcher = Matcher(nlp.vocab)\n",
        "#     pattern = [{\"LEMMA\": \"report\"}, \n",
        "#                {\"LEMMA\": \"you\"}]\n",
        "#     matcher.add(\"p1\", None, pattern)\n",
        "#     matches = matcher(x.doc)\n",
        "#     return NONTOXIC if len(matches)>0 else ABSTAIN"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d79sn121l1L4"
      },
      "source": [
        "@nlp_labeling_function()\n",
        "def contains_email(x):\n",
        "    \"\"\"If comment contains email address, label non-toxic, else abstain\"\"\"\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    pattern = [{\"LIKE_EMAIL\": True}]\n",
        "    matcher.add(\"p1\", None, pattern)\n",
        "    matches = matcher(x.doc)\n",
        "    return NONTOXIC if len(matches)>0 else ABSTAIN\n",
        "    \n",
        "@nlp_labeling_function()\n",
        "def contains_url(x):\n",
        "    \"\"\"If comment contains url, label non-toxic, else abstain\"\"\"\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    pattern = [{\"LIKE_URL\": True}]\n",
        "    matcher.add(\"p1\", None, pattern)\n",
        "    matches = matcher(x.doc)\n",
        "    return NONTOXIC if len(matches)>0 else ABSTAIN"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3I8PwUbl3pW"
      },
      "source": [
        "def keyword_lookup(x, keywords, label):\n",
        "    if any(word in x.text.lower() for word in keywords):\n",
        "        return label\n",
        "    return ABSTAIN\n",
        "\n",
        "def make_keyword_lf(keywords, label=TOXIC):\n",
        "    return LabelingFunction(\n",
        "        name=f\"keyword_{keywords[0]}\",\n",
        "        f=keyword_lookup,\n",
        "        resources=dict(keywords=keywords, label=label),\n",
        "    )\n",
        "\n",
        "# with open('badwords.txt') as f:\n",
        "#     toxic_stopwords = f.readlines()\n",
        "\n",
        "# toxic_stopwords = [x.strip() for x in toxic_stopwords] # len = 458\n",
        "# \"\"\"Comments mentioning at least one of Google's Toxic Stopwords \n",
        "# https://code.google.com/archive/p/badwordslist/downloads are likely toxic\"\"\"\n",
        "# keyword_toxic_stopwords = make_keyword_lf(keywords=toxic_stopwords)\n",
        "\n",
        "keyword_please = make_keyword_lf(keywords=[\"please\", \"plz\", \"pls\", \"pl\", \"Please read this\", \"Please read the\", \"Please read\"], label=NONTOXIC)\n",
        "\n",
        "keyword_thanks = make_keyword_lf(keywords=[\"thanks\", \"thank you\", \"thx\", \"tx\"], label=NONTOXIC)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8gnAGful6Cl"
      },
      "source": [
        "@labeling_function()\n",
        "def capslock(x):\n",
        "    \"\"\"If comment is written in all caps, label toxic, else abstain\"\"\"\n",
        "    return TOXIC if x.text == x.text.upper() else ABSTAIN"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGQfI0cbpSG2"
      },
      "source": [
        "lfs = [\n",
        "      contains_work_of_art,\n",
        "      contains_entity,\n",
        "      textblob_polarity,\n",
        "      textblob_subjectivity,\n",
        "      # contains_profanity,       # Removed: 62% accuracy, removed to make labeling faster\n",
        "      # contains_pleaseread,\n",
        "      contains_stopvandalizing,\n",
        "      # contains_harassme,        # Removed: 50% on 4 examples\n",
        "      # contains_willreport,      # Removed: labels 1 example and gets it wrong\n",
        "      contains_email,\n",
        "      contains_url,\n",
        "      # keyword_toxic_stopwords,  # Removed: 22% accuracy\n",
        "      keyword_please,\n",
        "      keyword_thanks,\n",
        "      # capslock                  # Removed: 55% accuracy, doesn't label many examples\n",
        "]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yIOHCbGp_uT"
      },
      "source": [
        "## Applying the Labeling Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXzxpW7PppcZ",
        "outputId": "2e9ab4b6-5510-43f0-fca2-5bdb6d649b19"
      },
      "source": [
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=train_df)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n",
            "100%|██████████| 30463/30463 [26:58<00:00, 18.82it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61ZFqTUrbvnM",
        "outputId": "e6ce76a6-0c08-4e69-b30c-38ec8aac69a9"
      },
      "source": [
        "L_val = applier.apply(df=val_df)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n",
            "100%|██████████| 7979/7979 [07:14<00:00, 18.38it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuUXPkf0qj9v",
        "outputId": "98c996e1-c25e-4180-ccdf-a16d9a4849cd"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('L_train_toxic_1.pkl','wb') as f:\n",
        "  pickle.dump(L_train, f)\n",
        "with open('L_train_toxic_1.pkl','rb') as f:\n",
        "  L_train = pickle.load(f)\n",
        "  print(L_train.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30463, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiH7zJhZBn9X",
        "outputId": "8d96468c-a63b-492f-e5b4-7787ec622736"
      },
      "source": [
        "L_train"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1, -1, -1, ..., -1, -1, -1],\n",
              "       [-1,  0, -1, ..., -1,  0, -1],\n",
              "       [-1, -1, -1, ..., -1,  0, -1],\n",
              "       ...,\n",
              "       [-1,  0, -1, ..., -1,  0, -1],\n",
              "       [-1,  0, -1, ..., -1,  0,  0],\n",
              "       [-1, -1, -1, ..., -1,  0, -1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "CK4UUygYaUTs",
        "outputId": "9aa43c1a-7a30-4bc6-8bb8-ac41d70d6da0"
      },
      "source": [
        "from snorkel.labeling import LFAnalysis\n",
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>contains_work_of_art</th>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.059843</td>\n",
              "      <td>0.053409</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_entity</th>\n",
              "      <td>1</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.298001</td>\n",
              "      <td>0.205922</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textblob_polarity</th>\n",
              "      <td>2</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.003709</td>\n",
              "      <td>0.002725</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textblob_subjectivity</th>\n",
              "      <td>3</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.171224</td>\n",
              "      <td>0.058563</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_pleaseread</th>\n",
              "      <td>4</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.002692</td>\n",
              "      <td>0.002692</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_stopvandalizing</th>\n",
              "      <td>5</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.004432</td>\n",
              "      <td>0.004038</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_email</th>\n",
              "      <td>6</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.001805</td>\n",
              "      <td>0.001444</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_url</th>\n",
              "      <td>7</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.030956</td>\n",
              "      <td>0.024719</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword_please</th>\n",
              "      <td>8</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.322588</td>\n",
              "      <td>0.214391</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword_thanks</th>\n",
              "      <td>9</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.080097</td>\n",
              "      <td>0.057053</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          j Polarity  Coverage  Overlaps  Conflicts\n",
              "contains_work_of_art      0      [0]  0.059843  0.053409        0.0\n",
              "contains_entity           1      [0]  0.298001  0.205922        0.0\n",
              "textblob_polarity         2      [0]  0.003709  0.002725        0.0\n",
              "textblob_subjectivity     3      [0]  0.171224  0.058563        0.0\n",
              "contains_pleaseread       4      [0]  0.002692  0.002692        0.0\n",
              "contains_stopvandalizing  5      [0]  0.004432  0.004038        0.0\n",
              "contains_email            6      [0]  0.001805  0.001444        0.0\n",
              "contains_url              7      [0]  0.030956  0.024719        0.0\n",
              "keyword_please            8      [0]  0.322588  0.214391        0.0\n",
              "keyword_thanks            9      [0]  0.080097  0.057053        0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sldAErC6aZix"
      },
      "source": [
        "from snorkel.labeling.model import LabelModel\n",
        "\n",
        "label_model = LabelModel(cardinality=2, verbose=True)\n",
        "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Iv14vWQEarCr",
        "outputId": "1a1caaee-42c1-40c6-c7fc-629bda1a04fa"
      },
      "source": [
        "val_df"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>155376</th>\n",
              "      <td>bcd794ddc143f4a1</td>\n",
              "      <td>(UTC)\\n\\nI wholeheartedly disagree. If you choose to annotate things using the Christian calendar, then AD should be the default. CE and BCE are and affront to the people whose calendar you're using. Use another calendar if you don't want to use the proper notation.   21:03, 11 March 2014</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72551</th>\n",
              "      <td>c2252b14e80ca744</td>\n",
              "      <td>Hello, please refrain from pushing your views on Wikipedia. I understand that you identify strongly with and support the values of the former illegal state: The Confederate States of America which was founded on the principals of racism and slavery. Since these are extremist and reactionary positions in our modern society, I recommend you think carefully about whether your contributions truly advance the goals of Wikipedia. Thank you.\\n\\nBest,\\n\\nAnonWikiCitizen</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112660</th>\n",
              "      <td>5ab4d9dd112bcf08</td>\n",
              "      <td>This is not an article about scholarship on the Cold War, but an article about the Cold War itself; scholarship of all sorts, traditional or not, should be allowed if reliable and germain.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115119</th>\n",
              "      <td>6786b6599e32031f</td>\n",
              "      <td>\"The problem with saying that Warren G. Harding was the first African-American President is that it is a theory that is unproven by fact.  While many people believe this concept - some even go to great lengths to self publish books on the topics, there is no way to scientifically prove the concept, nor is there any way to verify generally accepted documents that could show this is even a possibility.  The rumor that Harding was black rages about based on two quotes, one by Harding himself (where he says he doesn't know if it could be true, the other a rumor started by his future father-in-law meant to destroy Harding's business and reputation.) Consider verifiable these FACTS on the matter:\\n1) Harding's alleged \"\"black\"\" lineage can not be proven through United States Census forms, death certificate, or any other PRIMARY SOURCE document.  As far back as the 1850 census (the first to name all people enumerated, and designate their race) Harding's father and mother are enumerated as white.  This is most frequently dismissed by Harding Conspiracy followers who claim the census forms were doctored after the fact as part of a Federal Government cover-up.\\n\\n2) There is no DNA proof of Harding's alleged \"\"black blood\"\", (nor is there proof that Harding fathered Elizabeth Ann Christian).\\n\\n3) Harding was not raised as a cultural \"\"black\"\" that is to say that he was not raised within the black community, and therefore would have not had the same cultural experiences that other blacks in the era would have had.\\n\\n4) \"\"Black Harding\"\" promoters will point to William Estabrook Chancellor's book on Harding as proof of government conspiracy.  And it is interesting how swifty the government worked to squash the book and get its copies.  But if one looks at Chancellor's research methodology (and we step away from those who claim that the book was supressed) - all of it based on hearsay - any student in college today who would present this type of research in the form of a paper, masters thesis or dissertation would have been thrown out of college for faulty research!   \\n\\n5) Some of the promoters of this theory of Harding's \"\"blackness\"\" on \"\"family stories\"\".  While folklore is not always untrue, folklore can be embellished from storyteller to storyteller. Ask anyone who studies it, folklore is at the mercy of the one who passes it on.\\n\\n6) The promoters of these theories go to great lengths to attack the people who poke logical holes in their wishful arguments. They can not refute the facts, so they attack the people who question their beliefs. Take a look at the \"\"reviews\"\" of Harding books published in the past ten years in places like Amazon and B&amp;N; online and you'll get an idea how some people will attack those who do not buy into the black \"\"Black Harding\"\" myth.\\n\\nIf Wikipedia were to add information that Harding was the first black President, without irrfetable proof, it simply ads another chain in the long list of unrliable misinformation.   \\n\\n\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67586</th>\n",
              "      <td>b4de886da6ee092e</td>\n",
              "      <td>\"\\n\\n Pasttimes \\n\\nYou could say \"\"I'm onto you\"\", but I don't think that would convey an appropriate tone for how I really feel. Let me put it this way:\\n\\nI KNOW EXACTLY WHAT YOU GET UP TO IN YOUR SPARE TIME..........but I like it! Your \"\"secrets\"\" are safe with me, have no fear. 79.75.171.154  \"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142685</th>\n",
              "      <td>fb2db80423a463cb</td>\n",
              "      <td>\"\\nResponse much appreciated, thanks. Well, I'm trying to retain as much of your text as possible. There's a lot of good stuff in there which simply needs sourcing and updating in with the other material. That's why I abandoned the sandbox idea and thought it best to just run with what we have. The article is going to get massive in the next few weeks though to make it comprehensive as possible, but it'll be split and condensed later. I really do need your help if possible though on tracing the source of the unsourced material. I'll try to do what I can but I'll approach you if I can't find a source for something.♦  \"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101752</th>\n",
              "      <td>20816cc5ec4b8785</td>\n",
              "      <td>You're welcome to keep playing in the WP:Sandbox, but avoid attacks there, or elsewhere.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>10042fe4deb02bf5</td>\n",
              "      <td>Page name \\n\\nA user has reverted an edit that was going to include a UAV in the list.  The reason stated was that 'A UAV isn't a specific aircraft and the Army isn't part of the RAAF'.  There are quite a few aircraft in the list that are not part of the RAAF.  Moreover, all future helicopter purchases are most likely going to be either Army or RAN .  Therefore, we either remove all RAN and Army aircraft or we move the page to 'List of aircraft of the ADF'.  If you're up to it we can vote to move the page as below and I will do any changes (if any) next week (Mon 19th March).  -   \\nsupport - it will make the list more comprehensive and keep the current intent.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151010</th>\n",
              "      <td>75db0fcf5a806385</td>\n",
              "      <td>and I am a homosexual.  I think I am better Wikipedia user than you.  Please refrain from making edits to the site.  Thank you.  That is all, asswhipe.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79738</th>\n",
              "      <td>d555544a1dc13ef0</td>\n",
              "      <td>I use ST to create songs. I've mostly created Techno, Ind. Techno, House, Trance, and mayble a little more. -)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7979 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ... identity_hate\n",
              "155376  bcd794ddc143f4a1  ...             0\n",
              "72551   c2252b14e80ca744  ...             0\n",
              "112660  5ab4d9dd112bcf08  ...             0\n",
              "115119  6786b6599e32031f  ...             0\n",
              "67586   b4de886da6ee092e  ...             0\n",
              "...                  ...  ...           ...\n",
              "142685  fb2db80423a463cb  ...             0\n",
              "101752  20816cc5ec4b8785  ...             0\n",
              "5998    10042fe4deb02bf5  ...             0\n",
              "151010  75db0fcf5a806385  ...             0\n",
              "79738   d555544a1dc13ef0  ...             0\n",
              "\n",
              "[7979 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "wpYfjI6fajb0",
        "outputId": "e342fa4a-56af-42b4-ad7b-a2a71c6e84be"
      },
      "source": [
        "Y_val = val_df.labels.values\n",
        "LFAnalysis(L_val, lfs).lf_summary(Y_val)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "      <th>Correct</th>\n",
              "      <th>Incorrect</th>\n",
              "      <th>Emp. Acc.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>contains_work_of_art</th>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.079208</td>\n",
              "      <td>0.070811</td>\n",
              "      <td>0.0</td>\n",
              "      <td>605</td>\n",
              "      <td>27</td>\n",
              "      <td>0.957278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_entity</th>\n",
              "      <td>1</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.361073</td>\n",
              "      <td>0.255420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2719</td>\n",
              "      <td>162</td>\n",
              "      <td>0.943770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textblob_polarity</th>\n",
              "      <td>2</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.005640</td>\n",
              "      <td>0.003760</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>0.955556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textblob_subjectivity</th>\n",
              "      <td>3</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.112044</td>\n",
              "      <td>0.052262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>706</td>\n",
              "      <td>188</td>\n",
              "      <td>0.789709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_pleaseread</th>\n",
              "      <td>4</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.003509</td>\n",
              "      <td>0.003509</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_stopvandalizing</th>\n",
              "      <td>5</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.004888</td>\n",
              "      <td>0.004387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>0.974359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_email</th>\n",
              "      <td>6</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.001880</td>\n",
              "      <td>0.001504</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_url</th>\n",
              "      <td>7</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.039855</td>\n",
              "      <td>0.031959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>309</td>\n",
              "      <td>9</td>\n",
              "      <td>0.971698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword_please</th>\n",
              "      <td>8</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.391277</td>\n",
              "      <td>0.270836</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2940</td>\n",
              "      <td>182</td>\n",
              "      <td>0.941704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword_thanks</th>\n",
              "      <td>9</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.120566</td>\n",
              "      <td>0.084346</td>\n",
              "      <td>0.0</td>\n",
              "      <td>940</td>\n",
              "      <td>22</td>\n",
              "      <td>0.977131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          j Polarity  Coverage  ...  Correct  Incorrect  Emp. Acc.\n",
              "contains_work_of_art      0      [0]  0.079208  ...      605         27   0.957278\n",
              "contains_entity           1      [0]  0.361073  ...     2719        162   0.943770\n",
              "textblob_polarity         2      [0]  0.005640  ...       43          2   0.955556\n",
              "textblob_subjectivity     3      [0]  0.112044  ...      706        188   0.789709\n",
              "contains_pleaseread       4      [0]  0.003509  ...       28          0   1.000000\n",
              "contains_stopvandalizing  5      [0]  0.004888  ...       38          1   0.974359\n",
              "contains_email            6      [0]  0.001880  ...       15          0   1.000000\n",
              "contains_url              7      [0]  0.039855  ...      309          9   0.971698\n",
              "keyword_please            8      [0]  0.391277  ...     2940        182   0.941704\n",
              "keyword_thanks            9      [0]  0.120566  ...      940         22   0.977131\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmu1SGKIbmtW",
        "outputId": "df6d3dbe-5294-4407-d86e-439ff713d3eb"
      },
      "source": [
        "correct_examples = LFAnalysis(L_val, lfs).lf_summary(Y_val)['Correct'].sum()\n",
        "incorrect_examples = LFAnalysis(L_val, lfs).lf_summary(Y_val)['Incorrect'].sum()\n",
        "total_examples = correct_examples + incorrect_examples\n",
        "\n",
        "print('Number of Correct Examples: ' + str(correct_examples))\n",
        "print('Number of Correct Examples: ' + str(incorrect_examples))\n",
        "print('Percentage of Correct Examples: ' + str(100 * correct_examples / total_examples) + '%')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Correct Examples: 8343\n",
            "Number of Correct Examples: 593\n",
            "Percentage of Correct Examples: 93.363921217547%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgpBcB8_j30l"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True)\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenizer.tokenize, ngram_range=(1, 3))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4e9L7wllZk-"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state=42)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbhp1o4qldzI",
        "outputId": "7606bea4-fa91-432b-c19e-5af1d8b2af32"
      },
      "source": [
        "from snorkel.labeling import filter_unlabeled_dataframe\n",
        "from snorkel.utils import probs_to_preds\n",
        "snorkel_label_probs = label_model.predict_proba(L=L_train)\n",
        "X, y = filter_unlabeled_dataframe(X=train_df.text, y=snorkel_label_probs, L=L_train)\n",
        "X = vectorizer.fit_transform(X)\n",
        "classifier.fit(X, probs_to_preds(probs=y))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "5t5BDFdGlwgq",
        "outputId": "97410b68-c5d2-44a3-c746-47e0a390e021"
      },
      "source": [
        "X = vectorizer.transform(val_df.text.tolist())\n",
        "y_true = val_df.labels.values    \n",
        "y_pred = classifier.predict(X)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.92      1.00      0.96      7217\\n           1       0.91      0.19      0.31       762\\n\\n    accuracy                           0.92      7979\\n   macro avg       0.92      0.59      0.63      7979\\nweighted avg       0.92      0.92      0.90      7979\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI10y7xNmSxK",
        "outputId": "d22c87de-cd15-427e-9606-77bf18bd7206"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred, labels=[0,1]))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96      7217\n",
            "           1       0.91      0.19      0.31       762\n",
            "\n",
            "    accuracy                           0.92      7979\n",
            "   macro avg       0.92      0.59      0.63      7979\n",
            "weighted avg       0.92      0.92      0.90      7979\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86JmjWdWq0zh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}